# AI æç¤ºè¯å·¥ç¨‹æ•™ç¨‹ï¼šä» Superpowers é¡¹ç›®å­¦åˆ°çš„æœ€ä½³å®è·µ

> **æ•™ç¨‹ç‰ˆæœ¬**: 1.0
> **åŸºäºé¡¹ç›®**: [obra/superpowers](https://github.com/obra/superpowers)
> **é€‚ç”¨å¯¹è±¡**: AI åŠ©æ‰‹å¼€å‘è€…ã€æç¤ºè¯å·¥ç¨‹å¸ˆã€å›¢é˜Ÿå·¥å…·æ„å»ºè€…
> **å‰ç½®è¦æ±‚**: ç†Ÿæ‚‰åŸºæœ¬ç¼–ç¨‹æ¦‚å¿µï¼Œäº†è§£ AI å¯¹è¯ç³»ç»ŸåŸºç¡€

---

## ğŸ“š ç›®å½•

1. [å¼•è¨€ï¼šä¸ºä»€ä¹ˆæç¤ºè¯éœ€è¦å·¥ç¨‹åŒ–](#å¼•è¨€ä¸ºä»€ä¹ˆæç¤ºè¯éœ€è¦å·¥ç¨‹åŒ–)
2. [æ ¸å¿ƒè®¾è®¡åŸç†](#æ ¸å¿ƒè®¾è®¡åŸç†)
3. [ç»“æ„æ¨¡å¼ä¸€ï¼šç»Ÿä¸€çš„æŠ€èƒ½æ¨¡æ¿](#ç»“æ„æ¨¡å¼ä¸€ç»Ÿä¸€çš„æŠ€èƒ½æ¨¡æ¿)
4. [ç»“æ„æ¨¡å¼äºŒï¼šé“å¾‹å¼åŸåˆ™å¼ºè°ƒ](#ç»“æ„æ¨¡å¼äºŒé“å¾‹å¼åŸåˆ™å¼ºè°ƒ)
5. [å†…å®¹æ¨¡å¼ä¸€ï¼šé¢„åˆ¤å¿ƒç†é™·é˜±](#å†…å®¹æ¨¡å¼ä¸€é¢„åˆ¤å¿ƒç†é™·é˜±)
6. [å†…å®¹æ¨¡å¼äºŒï¼šè¯æ®é©±åŠ¨éªŒè¯](#å†…å®¹æ¨¡å¼äºŒè¯æ®é©±åŠ¨éªŒè¯)
7. [å·¥ä½œæµæ¨¡å¼ï¼šå¤šå±‚å®¡æŸ¥æœºåˆ¶](#å·¥ä½œæµæ¨¡å¼å¤šå±‚å®¡æŸ¥æœºåˆ¶)
8. [å®ç”¨æ¨¡æ¿åº“](#å®ç”¨æ¨¡æ¿åº“)
9. [å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ](#å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ)
10. [ä»ç¤ºä¾‹åˆ°å®è·µï¼šå®Œæ•´æ¡ˆä¾‹](#ä»ç¤ºä¾‹åˆ°å®è·µå®Œæ•´æ¡ˆä¾‹)

---

## å¼•è¨€ï¼šä¸ºä»€ä¹ˆæç¤ºè¯éœ€è¦å·¥ç¨‹åŒ–

### ä¼ ç»Ÿæç¤ºè¯çš„é—®é¢˜

æƒ³è±¡ä½ è¿™æ ·å’Œ AI å¯¹è¯ï¼š

```
ä½ ï¼šå¸®æˆ‘å®ç°ç”¨æˆ·ç™»å½•åŠŸèƒ½
AIï¼šå¥½çš„ï¼Œæˆ‘æ¥å†™ä»£ç ...
     [å†™äº†ä¸€å †ä»£ç ï¼Œæ²¡æœ‰æµ‹è¯•ï¼Œæ²¡æœ‰æ–‡æ¡£]
AIï¼šå®Œæˆäº†ï¼
ä½ ï¼šè®©æˆ‘çœ‹çœ‹... å¥½åƒæœ‰é—®é¢˜
AIï¼šå“¦ï¼Œè®©æˆ‘ä¿®ä¿®...
     [éšæœºä¿®æ”¹ï¼Œæ²¡æœ‰ç³»ç»Ÿæ€§è°ƒè¯•]
AIï¼šåº”è¯¥å¯ä»¥äº†
ä½ ï¼šæµ‹è¯•è¿˜æ˜¯å¤±è´¥...
```

è¿™ç§å¯¹è¯æ¨¡å¼çš„ç—›ç‚¹ï¼š
- âŒ æ²¡æœ‰æ˜ç¡®çš„æµç¨‹ï¼Œä¾èµ– AI "å‡­æ„Ÿè§‰"
- âŒ è´¨é‡æ— æ³•ä¿è¯ï¼Œéœ€è¦å¤šæ¬¡åå¤
- âŒ å®¹æ˜“äº§ç”Ÿ"å¹»è§‰"ï¼Œå£°ç§°å®Œæˆäº†å®é™…æ²¡æœ‰
- âŒ æ— æ³•åœ¨å›¢é˜Ÿé—´å¤ç”¨æˆåŠŸç»éªŒ

### å·¥ç¨‹åŒ–æç¤ºè¯çš„ä»·å€¼

Superpowers é¡¹ç›®å±•ç¤ºäº†å¦ä¸€ç§æ–¹å¼ï¼š

```
ä½ ï¼šå¸®æˆ‘å®ç°ç”¨æˆ·ç™»å½•åŠŸèƒ½
AIï¼š[ä½¿ç”¨ brainstorming æŠ€èƒ½] è®©æˆ‘ä»¬æ˜ç¡®éœ€æ±‚...
     [é—®ä¸€ç³»åˆ—é—®é¢˜ï¼Œé€æ­¥ç»†åŒ–éœ€æ±‚]
AIï¼š[ä½¿ç”¨ writing-plans æŠ€èƒ½] è¿™æ˜¯è¯¦ç»†çš„å®ç°è®¡åˆ’...
     [æ¯ä¸ªæ­¥éª¤ 2-5 åˆ†é’Ÿï¼ŒåŒ…å«å®Œæ•´ä»£ç ]
ä½ ï¼šæ‰¹å‡†è®¡åˆ’
AIï¼š[ä½¿ç”¨ test-driven-development æŠ€èƒ½] ç¬¬ä¸€æ­¥ï¼šå†™å¤±è´¥æµ‹è¯•...
     [çœ‹æµ‹è¯•å¤±è´¥ï¼Œç¡®è®¤æµ‹è¯•æœ‰æ•ˆ]
AIï¼š[æ‰§è¡Œ RED-GREEN-REFACTOR å¾ªç¯]
AIï¼š[ä½¿ç”¨ verification-before-completion æŠ€èƒ½] è¿è¡Œæµ‹è¯•...
     [å±•ç¤ºå®é™…è¾“å‡ºï¼Œ34/34 é€šè¿‡]
AIï¼š[ä½¿ç”¨ requesting-code-review æŠ€èƒ½] è¯·æ±‚ä»£ç å®¡æŸ¥...
AIï¼šå®¡æŸ¥é€šè¿‡ï¼Œç™»å½•åŠŸèƒ½å®Œæˆ
```

è¿™ç§æ–¹å¼çš„ä¼˜ç‚¹ï¼š
- âœ… æ˜ç¡®æµç¨‹ï¼Œæ¯ä¸€æ­¥éƒ½æœ‰éªŒè¯
- âœ… è´¨é‡å¯é¢„æœŸï¼Œç¬¦åˆå·¥ç¨‹æ ‡å‡†
- âœ… è¯æ®é©±åŠ¨ï¼Œä¸ä¾èµ–ä¸»è§‚åˆ¤æ–­
- âœ… å¯å¤ç”¨ï¼Œå›¢é˜Ÿå…±äº«ç›¸åŒæ¨¡å¼

**æ ¸å¿ƒå·®å¼‚**ï¼š

| ç»´åº¦ | ä¼ ç»Ÿæç¤ºè¯ | å·¥ç¨‹åŒ–æç¤ºè¯ |
|-----|----------|-------------|
| æµç¨‹ | éšæœºã€å³å…´ | ç³»ç»Ÿæ€§ã€å¯é‡å¤ |
| éªŒè¯ | "åº”è¯¥èƒ½è¡Œ" | "çœ‹å®ƒå®é™…é€šè¿‡" |
| è´¨é‡ | å–å†³äºè¿æ°” | ç”±æµç¨‹ä¿è¯ |
| å¤ç”¨ | æ¯æ¬¡é‡æ–°è®¾è®¡ | å¤ç”¨æˆåŠŸæ¨¡å¼ |
| å¯ç»´æŠ¤æ€§ | éš¾ä»¥æ”¹è¿› | æ¨¡å—åŒ–ã€å¯è¿­ä»£ |

---

## æ ¸å¿ƒè®¾è®¡åŸç†

### åŸç† 1ï¼šç³»ç»Ÿæ€§ä¼˜äºéšæœºæ€§

å·¥ç¨‹åŒ–æç¤ºè¯å°†**éšæ€§çš„æœ€ä½³å®è·µæ˜¾æ€§åŒ–**ä¸ºå¯éµå¾ªçš„æµç¨‹ã€‚

#### ç¤ºä¾‹ï¼šTDD çš„ RED-GREEN-REFACTOR

**ä¼ ç»Ÿåšæ³•**ï¼š
```
ç”¨æˆ·ï¼šå¸®æˆ‘å†™ä¸€ä¸ªé‡è¯•å‡½æ•°
AIï¼šå¥½çš„ï¼Œå†™ä¸€ä¸ªå‡½æ•°... [å†™ä»£ç ]
     åŠ ä¸€äº›é”™è¯¯å¤„ç†... [åŠ ä»£ç ]
     å†åŠ ä¸€äº›æ—¥å¿—... [åŠ ä»£ç ]
     å†™ä¸ªæµ‹è¯•éªŒè¯ä¸€ä¸‹... [æµ‹è¯•é€šè¿‡]
AIï¼šå®Œæˆäº†ï¼
```

**å·¥ç¨‹åŒ–åšæ³•**ï¼ˆæ¥è‡ª test-driven-development æŠ€èƒ½ï¼‰ï¼š

```markdown
### RED - Write Failing Test

Write one minimal test showing what should happen.

### Verify RED - Watch It Fail

**MANDATORY. Never skip.**

```bash
npm test path/to/test.test.ts
```

Confirm:
- Test fails (not errors)
- Failure message is expected
- Fails because feature missing (not typos)

**Test passes?** You're testing existing behavior. Fix test.

### GREEN - Minimal Code

Write simplest code to pass the test.

### Verify GREEN - Watch It Pass

**MANDATORY.**

```bash
npm test path/to/test.test.ts
```

Confirm:
- Test passes
- Other tests still pass
- Output pristine (no errors, warnings)

**Test fails?** Fix code, not test.

### REFACTOR - Clean Up

After green only:
- Remove duplication
- Improve names
- Extract helpers

Keep tests green. Don't add behavior.
```

**å…³é”®å·®å¼‚**ï¼š
- ä¼ ç»Ÿï¼šå†™ä»£ç  â†’ "ä¹Ÿè®¸èƒ½è¡Œ"
- å·¥ç¨‹åŒ–ï¼šå†™æµ‹è¯• â†’ **çœ‹å®ƒå¤±è´¥** â†’ å†™ä»£ç  â†’ **çœ‹å®ƒé€šè¿‡** â†’ æ¸…ç†

**ä¸ºä»€ä¹ˆç³»ç»Ÿæ€§æ›´å¥½**ï¼š
1. **å¯é¢„æµ‹**ï¼šçŸ¥é“æ¯ä¸€æ­¥æœŸæœ›ä»€ä¹ˆ
2. **å¯è¿½è¸ª**ï¼šçŸ¥é“åœ¨å“ªä¸€æ­¥å¤±è´¥
3. **å¯é‡å¤**ï¼šä¸åŒ AI ç”¨ç›¸åŒæµç¨‹å¾—åˆ°ç±»ä¼¼è´¨é‡
4. **å¯æ”¹è¿›**ï¼šæµç¨‹é—®é¢˜å¯ä»¥é’ˆå¯¹æ€§ä¼˜åŒ–

---

### åŸç† 2ï¼šè¯æ®ä¼˜äºå®£ç§°

å·¥ç¨‹åŒ–æç¤ºè¯è¦æ±‚**å®¢è§‚è¯æ®**è€Œéä¸»è§‚å£°ç§°ã€‚

#### ç¤ºä¾‹ï¼šéªŒè¯å‰å®Œæˆ

**ä¼ ç»Ÿåšæ³•**ï¼š
```
AIï¼šæˆ‘å·²ç»ä¿®å¤äº† bug
ç”¨æˆ·ï¼šçœŸçš„å—ï¼Ÿ
AIï¼šæ˜¯çš„ï¼Œåº”è¯¥æ²¡é—®é¢˜äº†
ç”¨æˆ·ï¼šè®©æˆ‘æµ‹è¯•ä¸€ä¸‹... è¿˜æ˜¯å¤±è´¥
```

**å·¥ç¨‹åŒ–åšæ³•**ï¼ˆæ¥è‡ª verification-before-completion æŠ€èƒ½ï¼‰ï¼š

```markdown
## The Gate Function

```
BEFORE claiming any status or expressing satisfaction:

1. IDENTIFY: What command proves this claim?
2. RUN: Execute FULL command (fresh, complete)
3. READ: Full output, check exit code, count failures
4. VERIFY: Does output confirm to claim?
   - If NO: State actual status with evidence
   - If YES: State claim WITH evidence
5. ONLY THEN: Make the claim

Skip any step = lying, not verifying
```

## Key Patterns

**Tests:**
```
âœ… [Run test command] [See: 34/34 pass] "All tests pass"
âŒ "Should pass now" / "Look correct"
```

**Agent delegation:**
```
âœ… Agent reports success â†’ Check VCS diff â†’ Verify changes â†’ Report actual state
âŒ Trust agent report
```
```

**å®é™…è¾“å‡ºç¤ºä¾‹**ï¼š

```
âœ… å·¥ç¨‹åŒ– AIï¼š
$ npm test
Test Suites: 1 passed, 1 total
Tests:       34 passed, 34 total
Snapshots:   0 total
Time:        2.456 s

All tests pass (34/34), build complete.

âŒ ä¼ ç»Ÿ AIï¼š
Tests should pass now. Done!
```

**ä¸ºä»€ä¹ˆè¯æ®é©±åŠ¨æ›´å¥½**ï¼š
1. **å®¢è§‚æ€§**ï¼šæµ‹è¯•è¾“å‡º vs ä¸»è§‚åˆ¤æ–­
2. **å¯éªŒè¯æ€§**ï¼šä»»ä½•äººå¯ä»¥é‡æ–°è¿è¡Œçœ‹åˆ°ç›¸åŒç»“æœ
3. **è´£ä»»æœºåˆ¶**ï¼šè¯æ®è¿«ä½¿ AI å¯¹ç»“æœè´Ÿè´£

---

### åŸç† 3ï¼šè§’è‰²åˆ†ç¦»ä¼˜äºè§’è‰²æ··æ·†

å·¥ç¨‹åŒ–æç¤ºè¯å°†**å¤æ‚ä»»åŠ¡æ‹†åˆ†ä¸ºå•ä¸€èŒè´£çš„è§’è‰²**ã€‚

#### ç¤ºä¾‹ï¼šSubagent-Driven-Development

**ä¼ ç»Ÿåšæ³•**ï¼š
```
ç”¨æˆ·ï¼šå¸®æˆ‘å®ç°ä»»åŠ¡
AIï¼šå¥½çš„ï¼Œæˆ‘æ¥å†™ä»£ç ...
     [åŒæ—¶è€ƒè™‘éœ€æ±‚ã€ä»£ç è´¨é‡ã€æµ‹è¯•ã€æ–‡æ¡£]
     [å®¹æ˜“é¡¾æ­¤å¤±å½¼ï¼Œè´¨é‡ä¸ä¸€è‡´]
AIï¼šå®Œæˆäº†ï¼
     [å¯èƒ½éœ€æ±‚æ²¡å¯¹é½ï¼Œæˆ–ä»£ç è´¨é‡æœ‰é—®é¢˜]
```

**å·¥ç¨‹åŒ–åšæ³•**ï¼ˆæ¥è‡ª subagent-driven-developmentï¼‰ï¼š

```markdown
## Spec Compliance Reviewer

**Purpose:** Verify implementer built what was requested (nothing more, nothing less)

**CRITICAL: Do Not Trust the Report**

The implementer finished suspiciously quickly. Their report may be incomplete,
inaccurate, or optimistic. You MUST verify everything independently.

**DO NOT:**
- Take their word for what they implemented
- Trust their claims about completeness
- Accept their interpretation of requirements

**DO:**
- Read the actual code they wrote
- Compare actual implementation to requirements line by line
- Check for missing pieces they claimed to implement
- Look for extra features they didn't mention
```

```markdown
## Code Quality Reviewer

**Purpose:** Verify implementation is well-built (clean, tested, maintainable)

**Only dispatch after spec compliance review passes.**
```

**è§’è‰²èŒè´£è¡¨**ï¼š

| è§’è‰² | èŒè´£ | ä¸å…³å¿ƒ |
|-----|------|-------|
| **Implementer** | å®ç°éœ€æ±‚ï¼Œå†™æµ‹è¯• | ä¸è¯„ä»·æ•´ä½“è´¨é‡ |
| **Spec Reviewer** | éªŒè¯ç¬¦åˆéœ€æ±‚ | ä¸çœ‹ä»£ç é£æ ¼ |
| **Code Quality Reviewer** | è¯„ä»·ä»£ç è´¨é‡ | ä¸çœ‹éœ€æ±‚å¯¹é½ |

**ä¸ºä»€ä¹ˆè§’è‰²åˆ†ç¦»æ›´å¥½**ï¼š
1. **ä¸“æ³¨æ€§**ï¼šæ¯ä¸ªè§’è‰²åªéœ€å…³æ³¨å•ä¸€èŒè´£
2. **å®¢è§‚æ€§**ï¼šSpec Reviewer ä¸å—ä»£ç è´¨é‡å½±å“
3. **ç³»ç»Ÿæ€§**ï¼šå¤šå±‚å®¡æŸ¥å½¢æˆé˜²å¾¡çºµæ·±

---

## ç»“æ„æ¨¡å¼ä¸€ï¼šç»Ÿä¸€çš„æŠ€èƒ½æ¨¡æ¿

Superpowers çš„æ¯ä¸ªæŠ€èƒ½éƒ½éµå¾ªç»Ÿä¸€çš„å…ƒæ•°æ®ç»“æ„ã€‚è¿™æ˜¯å¯å‘ç°æ€§å’Œå¯ç»´æŠ¤æ€§çš„åŸºç¡€ã€‚

### æ¨¡æ¿ç»“æ„

```markdown
---
name: skill-name
description: One-line description with trigger conditions and usage context
---

# Skill Name

## Overview
[ç®€æ´çš„ä¸€å¥è¯æ ¸å¿ƒåŸåˆ™]

## Core Principle / Iron Law
[é“å¾‹å¼è§„åˆ™ï¼Œå…¨å¤§å†™ï¼Œä¸å¯è¿å]

## When to Use
[æ˜ç¡®çš„ä½¿ç”¨æ¡ä»¶ï¼ŒåŒ…å«ä¾‹å¤–æƒ…å†µ]

## The Process / The Pattern
[è¯¦ç»†çš„æ­¥éª¤è¯´æ˜ï¼Œå¯èƒ½æ˜¯åˆ—è¡¨ã€æµç¨‹å›¾æˆ–è¡¨æ ¼]

## Examples
[æ­£åæ¡ˆä¾‹å¯¹æ¯”ï¼Œå…·ä½“ä»£ç ç¤ºä¾‹]

## Common Rationalizations
[é¢„åˆ¤å¹¶åé©³å¸¸è§å€Ÿå£ï¼Œè¡¨æ ¼å½¢å¼]

## Red Flags - STOP
[è­¦å‘Šä¿¡å·ï¼Œè¯´æ˜éœ€è¦åœæ­¢å¹¶é‡æ–°å¼€å§‹]

## Verification Checklist
[å®Œæˆå‰å¿…é¡»æ£€æŸ¥çš„é¡¹ç›®ï¼Œå‹¾é€‰æ¡†å½¢å¼]

## Integration
[ä¸å…¶ä»–æŠ€èƒ½çš„å…³ç³»ï¼Œä½•æ—¶è°ƒç”¨æ­¤æŠ€èƒ½]
```

---

### ç¤ºä¾‹å¯¹æ¯”ï¼šä¸‰ç§ä¸åŒçš„æŠ€èƒ½

#### ç¤ºä¾‹ 1ï¼šæµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆtest-driven-developmentï¼‰

```markdown
---
name: test-driven-development
description: Use when implementing any feature or bugfix, before writing implementation code
---

# Test-Driven Development (TDD)

## Overview

Write the test first. Watch it fail. Write minimal code to pass.

**Core principle:** If you didn't watch the test fail, you don't know if it tests the right thing.

**Violating the letter of the rules is violating the spirit of the rules.**

## When to Use

**Always:**
- New features
- Bug fixes
- Refactoring
- Behavior changes

**Exceptions (ask your human partner):**
- Throwaway prototypes
- Generated code
- Configuration files

Thinking "skip TDD just this once"? Stop. That's rationalization.

## The Iron Law

```
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
```

Write code before the test? Delete it. Start over.

**No exceptions:**
- Don't keep it as "reference"
- Don't "adapt" it while writing tests
- Don't look at it
- Delete means delete

Implement fresh from tests. Period.
```

**åˆ†æ**ï¼š
- âœ… `name` æ¸…æ™°ï¼š`test-driven-development`
- âœ… `description` ç²¾å‡†ï¼šè¯´æ˜ä½•æ—¶ä½¿ç”¨
- âœ… `Overview` ç®€æ´ï¼šä¸€å¥è¯æ ¸å¿ƒåŸåˆ™
- âœ… `Iron Law` é†’ç›®ï¼šå…¨å¤§å†™å¼ºè°ƒ
- âœ… ä¾‹å¤–æ˜ç¡®ï¼šéœ€è¦ç”¨æˆ·æˆæƒ

---

#### ç¤ºä¾‹ 2ï¼šç³»ç»Ÿæ€§è°ƒè¯•ï¼ˆsystematic-debuggingï¼‰

```markdown
---
name: systematic-debugging
description: Use when encountering any bug, test failure, or unexpected behavior, before proposing fixes
---

# Systematic Debugging

## Overview

Random fixes waste time and create new bugs. Quick patches mask underlying issues.

**Core principle:** ALWAYS find root cause before attempting fixes. Symptom fixes are failure.

**Violating the letter of this process is violating the spirit of debugging.**

## The Iron Law

```
NO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST
```

If you haven't completed Phase 1, you cannot propose fixes.

## When to Use

Use for ANY technical issue:
- Test failures
- Bugs in production
- Unexpected behavior
- Performance problems
- Build failures
- Integration issues

**Use this ESPECIALLY when:**
- Under time pressure (emergencies make guessing tempting)
- "Just one quick fix" seems obvious
- You've already tried multiple fixes
- Previous fix didn't work
- You don't fully understand the issue

**Don't skip when:**
- Issue seems simple (simple bugs have root causes too)
- You're in a hurry (rushing guarantees rework)
- Manager wants it fixed NOW (systematic is faster than thrashing)

## The Four Phases

You MUST complete each phase before proceeding to next.

### Phase 1: Root Cause Investigation

**BEFORE attempting ANY fix:**

1. **Read Error Messages Carefully**
   - Don't skip past errors or warnings
   - They often contain exact solution
   - Read stack traces completely
   - Note line numbers, file paths, error codes

2. **Reproduce Consistently**
   - Can you trigger it reliably?
   - What are the exact steps?
   - Does it happen every time?
   - If not reproducible â†’ gather more data, don't guess

3. **Check Recent Changes**
   - What changed that could cause this?
   - Git diff, recent commits
   - New dependencies, config changes
   - Environmental differences

### Phase 2: Pattern Analysis

Find the pattern before fixing:

1. **Find Working Examples**
   - Locate similar working code in same codebase
   - What works that's similar to what's broken?

2. **Compare Against References**
   - If implementing pattern, read reference implementation COMPLETELY
   - Don't skim - read every line
   - Understand pattern fully before applying

### Phase 3: Hypothesis and Testing

**Scientific method:**

1. **Form Single Hypothesis**
   - State clearly: "I think X is the root cause because Y"
   - Write it down
   - Be specific, not vague

2. **Test Minimally**
   - Make the SMALLEST possible change to test hypothesis
   - One variable at a time
   - Don't fix multiple things at once

### Phase 4: Implementation

Fix the root cause, not the symptom:

1. **Create Failing Test Case**
   - Simplest possible reproduction
   - Automated test if possible
   - One-off test script if no framework
   - MUST have before fixing

2. **Implement Single Fix**
   - Address the root cause identified
   - ONE change at a time
   - No "while I'm here" improvements
   - No bundled refactoring
```

**åˆ†æ**ï¼š
- âœ… æµç¨‹æ¸…æ™°ï¼šå››ä¸ªé˜¶æ®µï¼Œé¡ºåºæ˜ç¡®
- âœ… å¼ºè°ƒé˜¶æ®µé—´ä¾èµ–ï¼šMUST complete each phase before proceeding
- âœ… æ¯é˜¶æ®µå…·ä½“ï¼šæ­¥éª¤å¯æ“ä½œï¼Œä¸æ˜¯æ¨¡ç³Šå»ºè®®

---

#### ç¤ºä¾‹ 3ï¼šéªŒè¯å‰å®Œæˆï¼ˆverification-before-completionï¼‰

```markdown
---
name: verification-before-completion
description: Use when about to claim work is complete, fixed, or passing, before committing or creating PRs - requires running verification commands and confirming output before making any success claims; evidence before assertions always
---

# Verification Before Completion

## Overview

Claiming work is complete without verification is dishonesty, not efficiency.

**Core principle:** Evidence before claims, always.

**Violating the letter of this rule is violating the spirit of this rule.**

## The Iron Law

```
NO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE
```

If you haven't run the verification command in this message, you cannot claim it passes.

## The Gate Function

```
BEFORE claiming any status or expressing satisfaction:

1. IDENTIFY: What command proves this claim?
2. RUN: Execute FULL command (fresh, complete)
3. READ: Full output, check exit code, count failures
4. VERIFY: Does output confirm to claim?
   - If NO: State actual status with evidence
   - If YES: State claim WITH evidence
5. ONLY THEN: Make the claim

Skip any step = lying, not verifying
```

## Common Failures

| Claim | Requires | Not Sufficient |
|-------|----------|----------------|
| Tests pass | Test command output: 0 failures | Previous run, "should pass" |
| Linter clean | Linter output: 0 errors | Partial check, extrapolation |
| Build succeeds | Build command: exit 0 | Linter passing, logs look good |
| Bug fixed | Test original symptom: passes | Code changed, assumed fixed |
| Regression test works | Red-green cycle verified | Test passes once |
| Agent completed | VCS diff shows changes | Agent reports "success" |
| Requirements met | Line-by-line checklist | Tests passing |

## Red Flags - STOP

- Using "should", "probably", "seems to"
- Expressing satisfaction before verification ("Great!", "Perfect!", "Done!", etc.)
- About to commit/push/PR without verification
- Trusting agent success reports
- Relying on partial verification
- Thinking "just this once"
- Tired and wanting work over
- **ANY wording implying success without having run verification**

## Key Patterns

**Tests:**
```
âœ… [Run test command] [See: 34/34 pass] "All tests pass"
âŒ "Should pass now" / "Look correct"
```

**Build:**
```
âœ… [Run build] [See: exit 0] "Build passes"
âŒ "Linter passed" (linter doesn't check compilation)
```

**Agent delegation:**
```
âœ… Agent reports success â†’ Check VCS diff â†’ Verify changes â†’ Report actual state
âŒ Trust agent report
```
```

**åˆ†æ**ï¼š
- âœ… è¡¨æ ¼åŒ–ï¼šCommon Failures å’Œ Key Patterns ä½¿ç”¨è¡¨æ ¼ï¼Œå¯¹æ¯”æ¸…æ™°
- âœ… å…·ä½“ç¤ºä¾‹ï¼šâœ… å’Œ âŒ æ ‡è®°æ­£ç¡®å’Œé”™è¯¯åšæ³•
- âœ… è­¦å‘Šå¼ºçƒˆï¼šRed Flags åˆ—å‡ºæ˜ç¡®çš„åœæ­¢ä¿¡å·

---

### æ¨¡æ¿ä½¿ç”¨æŒ‡å—

#### æ­¥éª¤ 1ï¼šå®šä¹‰å…ƒæ•°æ®

```yaml
---
name: your-skill-name              # ä½¿ç”¨ kebab-caseï¼Œæ¸…æ™°æè¿°åŠŸèƒ½
description: Use when [trigger condition], before [action] or when [context]
---
```

**æŠ€å·§**ï¼š
- `name`: ç®€çŸ­ã€æè¿°æ€§ã€kebab-case
- `description`: åŒ…å«ä½¿ç”¨æ¡ä»¶å’Œè§¦å‘è¯ï¼Œ100-150 å­—ç¬¦

**ç¤ºä¾‹**ï¼š
```yaml
# âŒ ä¸å¥½
name: debugging
description: Helps with bugs

# âœ… å¥½
name: systematic-debugging
description: Use when encountering any bug, test failure, or unexpected behavior, before proposing fixes
```

#### æ­¥éª¤ 2ï¼šç¼–å†™ Overview

**åŸåˆ™**ï¼š
- ä¸€å¥è¯æ ¸å¿ƒåŸåˆ™
- å¿…è¦æ—¶åŠ ä¸€å¥è§£é‡Š
- é¿å…å†—é•¿

**ç¤ºä¾‹**ï¼š

```markdown
# âŒ ä¸å¥½
## Overview
This skill helps you debug issues by following a systematic approach
that involves finding root causes, forming hypotheses, and
testing them before implementing fixes. This is important because...

# âœ… å¥½
## Overview

Random fixes waste time and create new bugs. Quick patches mask underlying issues.

**Core principle:** ALWAYS find root cause before attempting fixes.
```

#### æ­¥éª¤ 3ï¼šè®¾è®¡ Iron Law

**æ ¼å¼**ï¼š
- å…¨å¤§å†™
- ä½¿ç”¨ä»£ç å—
- ç«‹å³é…åæœè¯´æ˜

**ç¤ºä¾‹**ï¼š

```markdown
## The Iron Law

```
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
```

Write code before test? Delete it. Start over.

**No exceptions:**
- Don't keep it as "reference"
- Don't "adapt" it while writing tests
- Delete means delete
```

#### æ­¥éª¤ 4ï¼šç»“æ„åŒ–ä½¿ç”¨åœºæ™¯

**æ¨¡æ¿**ï¼š

```markdown
## When to Use

**Always:**
- [condition 1]
- [condition 2]

**Exceptions (ask your human partner):**
- [condition 1]
- [condition 2]

**Use this ESPECIALLY when:**
- [condition 1]
- [condition 2]

**Don't skip when:**
- [condition 1]
- [condition 2]
```

---

## ç»“æ„æ¨¡å¼äºŒï¼šé“å¾‹å¼åŸåˆ™å¼ºè°ƒ

é“å¾‹å¼åŸåˆ™é€šè¿‡**é†’ç›®çš„è§†è§‰è®¾è®¡**å’Œ**ç»å¯¹åŒ–çš„è¯­è¨€**å¼ºåŒ–å…³é”®è§„åˆ™ï¼Œä½¿å…¶æ— æ³•è¢«å¿½ç•¥æˆ–åˆç†åŒ–ç»•è¿‡ã€‚

### é“å¾‹çš„è®¾è®¡è¦ç´ 

#### è¦ç´  1ï¼šå…¨å¤§å†™ä»£ç å—

```markdown
## The Iron Law

```
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
```
```

**ä¸ºä»€ä¹ˆæœ‰æ•ˆ**ï¼š
- ä»£ç å—åœ¨è§†è§‰ä¸Šçªå‡º
- å…¨å¤§å†™ä¼ è¾¾ç´§è¿«æ„Ÿ
- ç®€çŸ­æœ‰åŠ›ï¼Œæ˜“è®°å¿†

#### è¦ç´  2ï¼šç«‹å³åæœè¯´æ˜

```markdown
```
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
```

Write code before test? Delete it. Start over.

**No exceptions:**
- Don't keep it as "reference"
- Don't "adapt" it while writing tests
- Don't look at it
- Delete means delete
```

**ä¸ºä»€ä¹ˆæœ‰æ•ˆ**ï¼š
- ç›´æ¥å›ç­”"è¿ååæ€ä¹ˆåŠ"
- æ¶ˆé™¤æ¨¡ç³Šç©ºé—´ï¼ˆ"ä¹Ÿè®¸å¯ä»¥..."ï¼‰
- å…·ä½“è¡ŒåŠ¨ï¼ˆåˆ é™¤ï¼Œè€ŒéæŠ½è±¡å»ºè®®ï¼‰

#### è¦ç´  3ï¼šè¿åè­¦å‘Š

```markdown
**Violating the letter of this rule is violating the spirit of the rule.**
```

æˆ–

```markdown
Skip any step = lying, not verifying
```

**ä¸ºä»€ä¹ˆæœ‰æ•ˆ**ï¼š
- é¢„åˆ¤å¸¸è§ç»•è¿‡ç†ç”±ï¼ˆ"å­—é¢æ„æ€ vs ç²¾ç¥"ï¼‰
- ä½¿ç”¨å¼ºçƒˆè¯æ±‡ï¼ˆlyingã€not verifyingï¼‰
- æ¶ˆé™¤"ç°è‰²åœ°å¸¦"

---

### å®ä¾‹å¯¹æ¯”ï¼šé“å¾‹ vs æ™®é€šå»ºè®®

#### åœºæ™¯ï¼šæµ‹è¯•é©±åŠ¨å¼€å‘

**âŒ æ™®é€šå»ºè®®**ï¼š

```markdown
## Testing Guidelines

It's important to write tests before writing code. This helps ensure
you're testing the right behavior and not just verifying your
implementation.

Try to follow TDD when possible:
1. Write a test
2. Implement the feature
3. Run the test to verify
4. Refactor if needed
```

**é—®é¢˜**ï¼š
- æŸ”å’Œè¯­è¨€ï¼ˆ"important"ã€"try to"ã€"possible"ï¼‰
- å…è®¸ä¾‹å¤–ï¼ˆ"when possible"ï¼‰
- æ— æ˜ç¡®åæœ
- å®¹æ˜“è¢«åˆç†åŒ–ç»•è¿‡

---

**âœ… é“å¾‹è®¾è®¡**ï¼ˆTDD æŠ€èƒ½ï¼‰ï¼š

```markdown
## The Iron Law

```
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
```

Write code before test? Delete it. Start over.

**No exceptions:**
- Don't keep it as "reference"
- Don't "adapt" it while writing tests
- Don't look at it
- Delete means delete

Implement fresh from tests. Period.
```

**ä¼˜åŠ¿**ï¼š
- ç»å¯¹åŒ–è¯­è¨€ï¼ˆNOã€WITHOUTï¼‰
- æ˜ç¡®åæœï¼ˆDelete itï¼‰
- æ¶ˆé™¤ä¾‹å¤–ï¼ˆNo exceptionsï¼‰
- é‡å¤å¼ºè°ƒï¼ˆPeriodï¼‰

---

#### åœºæ™¯ï¼šéªŒè¯å‰å®Œæˆ

**âŒ æ™®é€šå»ºè®®**ï¼š

```markdown
## Verification

Before claiming work is complete, you should run the appropriate
verification commands to make sure everything is working as expected.

Common verification steps:
- Run tests to ensure they pass
- Check linting errors
- Verify the build succeeds
```

**é—®é¢˜**ï¼š
- å»ºè®®è¯­æ°”ï¼ˆ"should"ã€"make sure"ï¼‰
- åˆ—ä¸¾è€Œéæµç¨‹
- æ— æ˜ç¡®é¡ºåº
- å…è®¸"éƒ¨åˆ†éªŒè¯"

---

**âœ… é“å¾‹è®¾è®¡**ï¼ˆverification-before-completion æŠ€èƒ½ï¼‰ï¼š

```markdown
## The Iron Law

```
NO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE
```

If you haven't run the verification command in this message, you cannot claim it passes.

## The Gate Function

```
BEFORE claiming any status or expressing satisfaction:

1. IDENTIFY: What command proves this claim?
2. RUN: Execute FULL command (fresh, complete)
3. READ: Full output, check exit code, count failures
4. VERIFY: Does output confirm to claim?
   - If NO: State actual status with evidence
   - If YES: State claim WITH evidence
5. ONLY THEN: Make the claim

Skip any step = lying, not verifying
```

**ä¼˜åŠ¿**ï¼š
- æµç¨‹åŒ–ï¼ˆGate Functionï¼‰
- æ­¥éª¤æ˜ç¡®ï¼ˆ1-5ï¼‰
- æ¯æ­¥å¯éªŒè¯
- å¼ºçƒˆè­¦å‘Šï¼ˆSkip any step = lyingï¼‰

---

### é“å¾‹è®¾è®¡æ¨¡æ¿

#### æ¨¡æ¿ 1ï¼šç¦æ­¢å¼é“å¾‹

```markdown
## The Iron Law

```
NO [FORBIDDEN ACTION] WITHOUT [REQUIRED CONDITION]
```

[What happens if violated]? [Immediate consequence].

**No exceptions:**
- [Don't do workaround 1]
- [Don't do workaround 2]
- [Don't do workaround 3]
```

**ä½¿ç”¨åœºæ™¯**ï¼šå¿…é¡»å…ˆæœ‰ Xï¼Œæ‰èƒ½åš Y

**ç¤ºä¾‹**ï¼š
```markdown
## The Iron Law

```
NO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST
```

If you haven't completed Phase 1, you cannot propose fixes.

**No exceptions:**
- Don't "try this first, then investigate"
- Don't fix "obvious" issues without understanding
- Don't proceed without confirming root cause
```

---

#### æ¨¡æ¿ 2ï¼šæµç¨‹å¼é“å¾‹

```markdown
## The Iron Law

```
[MANDATORY PROCESS IN ALL CAPS]
```

[Step-by-step required actions].

**If [condition]:**
- [Required action 1]
- [Required action 2]

**Never:**
- [Forbidden action 1]
- [Forbidden action 2]
```

**ä½¿ç”¨åœºæ™¯**ï¼šå¿…é¡»æŒ‰é¡ºåºæ‰§è¡Œæ­¥éª¤

**ç¤ºä¾‹**ï¼š
```markdown
## The Iron Law

```
BEFORE CLAIMING COMPLETION: VERIFY EVIDENCE FIRST
```

1. IDENTIFY: What command proves this claim?
2. RUN: Execute FULL command (fresh, complete)
3. READ: Full output, check exit code
4. VERIFY: Does output confirm to claim?
5. ONLY THEN: Make the claim

**Never:**
- Claim without running verification
- Use "should" or "probably"
- Express satisfaction before verification
```

---

#### æ¨¡æ¿ 3ï¼šç»å¯¹å¼é“å¾‹

```markdown
## The Iron Law

```
[ABSOLUTE RULE IN ALL CAPS]
```

[Immediate, unavoidable consequence].

**No exceptions:**
- [Not even when...]
- [Not even if...]
- [No "special circumstances"]

[Reinforcing statement].
```

**ä½¿ç”¨åœºæ™¯**ï¼šæ— è®ºä»€ä¹ˆæƒ…å†µéƒ½å¿…é¡»éµå®ˆ

**ç¤ºä¾‹**ï¼š
```markdown
## The Iron Law

```
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
```

Write code before test? Delete it. Start over.

**No exceptions:**
- Not even for "exploratory code"
- Not even for "prototypes"
- Not even if you're "just testing"

Violating the letter of this rule is violating the spirit of the rule.
```

---

## å†…å®¹æ¨¡å¼ä¸€ï¼šé¢„åˆ¤å¿ƒç†é™·é˜±

äººç±»ï¼ˆå’Œ AIï¼‰ä¼šæœ¬èƒ½åœ°å¯»æ‰¾æ·å¾„ã€åˆç†åŒ–å¤±è´¥ã€è¿‡åº¦è‡ªä¿¡ã€‚Superpowers é€šè¿‡é¢„åˆ¤è¿™äº›å¿ƒç†é™·é˜±å¹¶æå‰åé©³ï¼Œæ˜¾è‘—æé«˜äº†æµç¨‹çš„éµå®ˆç‡ã€‚

### å¸¸è§å¿ƒç†é™·é˜±åŠåº”å¯¹

#### é™·é˜± 1ï¼šæ²‰æ²¡æˆæœ¬è°¬è¯¯

**è®¤çŸ¥åå·®**ï¼š
```
"å·²ç»èŠ±äº† X å°æ—¶å†™è¿™æ®µä»£ç ï¼Œç°åœ¨åˆ é™¤é‡æ–°å¼€å§‹å¤ªæµªè´¹äº†"
```

**é¢„åˆ¤åé©³**ï¼ˆTDD æŠ€èƒ½ï¼‰ï¼š

```markdown
## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "Deleting X hours of work is wasteful" | Sunk cost fallacy. The time is already gone. Your choice now: Delete and rewrite with TDD (X more hours, high confidence) OR Keep it and add tests after (30 min, low confidence, likely bugs) |
```

**ä¸ºä»€ä¹ˆæœ‰æ•ˆ**ï¼š
1. æ˜¾æ€§åŒ–ï¼šå°†éšæ€§çš„"æ²‰æ²¡æˆæœ¬"æ¦‚å¿µå…·è±¡åŒ–
2. é‡åŒ–ï¼šç”¨å…·ä½“æ•°å­—å¯¹æ¯”ï¼ˆX hours vs 30 minï¼‰
3. ç»“æœå¯¼å‘ï¼šå¼ºè°ƒ"ä¿¡å¿ƒ"å’Œ"bug"çš„åæœ

---

#### é™·é˜± 2ï¼šç¡®è®¤åè¯¯

**è®¤çŸ¥åå·®**ï¼š
```
"æµ‹è¯•åå†™èƒ½è¾¾åˆ°ç›¸åŒç›®æ ‡ï¼Œåªæ˜¯é¡ºåºä¸åŒ"
```

**é¢„åˆ¤åé©³**ï¼ˆTDD æŠ€èƒ½ï¼‰ï¼š

```markdown
## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "Tests after achieve the same goals" | Tests-after answer "What does this do?" Tests-first answer "What should this do?" Tests-after are biased by your implementation. You test what you built, not what's required. |
```

**ä¸ºä»€ä¹ˆæœ‰æ•ˆ**ï¼š
1. é—®é¢˜å¯¹æ¯”ï¼šæ˜ç¡®æµ‹è¯•å‰åé—®çš„é—®é¢˜ä¸åŒ
2. åå·®æ¥æºï¼šæŒ‡å‡º"biased by your implementation"
3. è¯æ®å·®å¼‚ï¼šåŒºåˆ†"éªŒè¯å®ç°"vs"éªŒè¯éœ€æ±‚"

---

#### é™·é˜± 3ï¼šè¿‡åº¦è‡ªä¿¡

**è®¤çŸ¥åå·®**ï¼š
```
"è¿™å¾ˆç®€å•ï¼Œä¸éœ€è¦é‚£ä¹ˆä¸¥æ ¼çš„æµç¨‹"
```

**é¢„åˆ¤åé©³**ï¼ˆsystematic-debugging æŠ€èƒ½ï¼‰ï¼š

```markdown
## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "Issue is simple, don't need process" | Simple issues have root causes too. Process is fast for simple bugs. |
```

**ä¸ºä»€ä¹ˆæœ‰æ•ˆ**ï¼š
1. æ‰¿è®¤ï¼šæ‰¿è®¤"ç®€å•"ï¼Œä½†æŒ‡å‡º"ä¹Ÿæœ‰æ ¹æœ¬åŸå› "
2. æ•ˆç‡ï¼šå¼ºè°ƒ"æµç¨‹å¯¹ç®€å• Bug å¾ˆå¿«"
3. é‡æ„ï¼šå°†"æµªè´¹æ—¶é—´"è½¬ä¸º"èŠ‚çœæ—¶é—´"

---

#### é™·é˜± 4ï¼šåˆç†åŒ–ä¾‹å¤–

**è®¤çŸ¥åå·®**ï¼š
```
"è¿™æ¬¡ç‰¹æ®Šï¼Œä¸‹æ¬¡å†éµå®ˆè§„åˆ™"
```

**é¢„åˆ¤åé©³**ï¼ˆverification-before-completion æŠ€èƒ½ï¼‰ï¼š

```markdown
## Rationalization Prevention

| Excuse | Reality |
|--------|---------|
| "Just this once" | No exceptions |
| "Different words so rule doesn't apply" | Spirit over letter |
```

**ä¸ºä»€ä¹ˆæœ‰æ•ˆ**ï¼š
1. ç»å¯¹åŒ–ï¼š"No exceptions" æ¶ˆé™¤ç°è‰²åœ°å¸¦
2. é€’å½’é¢„é˜²ï¼šé¢„åˆ¤"æ”¹æªè¾ç»•è¿‡"çš„å°è¯•
3. ç®€çŸ­æœ‰åŠ›ï¼šç®€æ´å¯¹æ¯”ï¼Œæ˜“è®°å¿†

---

### å¦‚ä½•è¯†åˆ«éœ€è¦é¢„åˆ¤çš„é™·é˜±

#### æ­¥éª¤ 1ï¼šæ”¶é›†å¸¸è§å¤±è´¥æ¨¡å¼

è§‚å¯Ÿå®é™…ä½¿ç”¨ä¸­ç”¨æˆ·/AI çš„å¸¸è§è¡Œä¸ºï¼š

```
è§‚å¯Ÿè®°å½•ï¼š
- ç”¨æˆ·è¯´"å…ˆå¿«é€Ÿå†™ä¸ªåŸå‹" â†’ åæ¥æ²¡æœ‰éµå¾ª TDD
- AI è¯´"åº”è¯¥èƒ½è¡Œ" â†’ å®é™…æµ‹è¯•å¤±è´¥
- ç”¨æˆ·è¯´"ç´§æ€¥æƒ…å†µï¼Œè·³è¿‡æµç¨‹" â†’ å¯¼è‡´æ›´å¤šé—®é¢˜
```

#### æ­¥éª¤ 2ï¼šè¯†åˆ«èƒŒåçš„è®¤çŸ¥åå·®

å°†è¡Œä¸ºæ˜ å°„åˆ°è®¤çŸ¥å¿ƒç†å­¦æ¦‚å¿µï¼š

```
è¡Œä¸º â†’ è®¤çŸ¥åå·®
"å…ˆå†™åŸå‹" â†’ è§„åˆ’è°¬è¯¯ï¼ˆä½ä¼°å¤æ‚æ€§ï¼‰
"åº”è¯¥èƒ½è¡Œ" â†’ è¿‡åº¦è‡ªä¿¡ï¼ˆé«˜ä¼°èƒ½åŠ›ï¼‰
"ç´§æ€¥è·³è¿‡" â†’ ç°åœ¨åå·®ï¼ˆç°åœ¨ä¼˜å…ˆäºæœªæ¥ï¼‰
```

#### æ­¥éª¤ 3ï¼šè®¾è®¡åé©³ç­–ç•¥

**ç­–ç•¥ 1ï¼šæ˜¾æ€§åŒ–**

```markdown
| Excuse | Reality |
|--------|---------|
| "Just this once" | This is rationalization, not exception |
```

**ç­–ç•¥ 2ï¼šé‡åŒ–åæœ**

```markdown
| Excuse | Reality |
|--------|---------|
| "Deleting X hours is wasteful" | Choice now: X hours with high confidence vs 30 min with low confidence |
```

**ç­–ç•¥ 3ï¼šé‡æ„æ¡†æ¶**

```markdown
| Excuse | Reality |
|--------|---------|
| "Process is slow" | Process is FASTER than debugging guess-and-check (15-30 min vs 2-3 hours) |
```

---

### Common Rationalizations æ¨¡æ¿

#### æ¨¡æ¿ 1ï¼šè¡¨æ ¼å½¢å¼

```markdown
## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "[User's common excuse]" | [Why it's wrong, concisely |
| "[Another excuse]" | [Why it's wrong, concisely |
```

**ç¤ºä¾‹**ï¼š

```markdown
## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "Too simple to test" | Simple code breaks. Test takes 30 seconds. |
| "I'll test after" | Tests passing immediately prove nothing. |
| "Already manually tested" | Ad-hoc â‰  systematic. No record, can't re-run. |
```

---

#### æ¨¡æ¿ 2ï¼šè¡¨æ ¼ + åŸç†è¯´æ˜

```markdown
## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "[Excuse]" | [Direct refutation] |

**Why this matters:**
- [Reason 1]
- [Reason 2]
```

**ç¤ºä¾‹**ï¼š

```markdown
## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "Tests after achieve same goals - it's spirit not ritual" | No. Tests-after answer "What does this do?" Tests-first answer "What should this do?" |

**Why this matters:**
- Tests-after verify you remembered everything (you didn't)
- Tests-first force edge case discovery before implementing
- 30 minutes of tests after â‰  TDD. You get coverage, lose proof tests work.
```

---

#### æ¨¡æ¿ 3ï¼šRationalization Prevention

```markdown
## Rationalization Prevention

| Excuse | Reality |
|--------|---------|
| "[Excuse 1]" | [Refutation] |
| "[Excuse 2]" | [Refutation] |
| "[Excuse 3]" | [Refutation] |
| "[Excuse 4]" | [Refutation] |
| "[Excuse 5]" | [Refutation] |
| "[Excuse 6]" | [Refutation] |
```

**ç¤ºä¾‹**ï¼ˆverification-before-completion æŠ€èƒ½ï¼‰ï¼š

```markdown
## Rationalization Prevention

| Excuse | Reality |
|--------|---------|
| "Should work now" | RUN verification |
| "I'm confident" | Confidence â‰  evidence |
| "Just this once" | No exceptions |
| "Linter passed" | Linter â‰  compiler |
| "Agent said success" | Verify independently |
| "I'm tired" | Exhaustion â‰  excuse |
| "Partial check is enough" | Partial proves nothing |
| "Different words so rule doesn't apply" | Spirit over letter |
```

---

## å†…å®¹æ¨¡å¼äºŒï¼šè¯æ®é©±åŠ¨éªŒè¯

è¯æ®é©±åŠ¨éªŒè¯å°†**ä¸»è§‚å®£ç§°è½¬åŒ–ä¸ºå®¢è§‚å¯éªŒè¯çš„äº‹å®**ï¼Œé€šè¿‡è¦æ±‚å…·ä½“è¯æ®æ¶ˆé™¤æ¨¡ç³Šç©ºé—´å’Œ"å¹»è§‰"ã€‚

### è¯æ®é©±åŠ¨ vs ä¸»è§‚å®£ç§°

#### åœºæ™¯ 1ï¼šæµ‹è¯•éªŒè¯

**âŒ ä¸»è§‚å®£ç§°**ï¼š

```
AIï¼šTests should pass now. Done!
ç”¨æˆ·ï¼šçœŸçš„å—ï¼Ÿ
AIï¼šI'm confident it works.
ç”¨æˆ·ï¼šLet me check... [tests fail]
```

**é—®é¢˜**ï¼š
- ä½¿ç”¨"should"ï¼ˆä¸ç¡®å®šï¼‰
- ä¾èµ–"confidence"ï¼ˆä¸»è§‚ï¼‰
- æ— å®é™…è¯æ®

---

**âœ… è¯æ®é©±åŠ¨**ï¼ˆverification-before-completion æŠ€èƒ½ï¼‰ï¼š

```markdown
**Tests:**
```
âœ… [Run test command] [See: 34/34 pass] "All tests pass"
âŒ "Should pass now" / "Look correct"
```

**å®é™…è¾“å‡º**ï¼š

```
$ npm test

Test Suites: 1 passed, 1 total
Tests:       34 passed, 34 total
Snapshots:   0 total
Time:        2.456 s

All tests pass (34/34).
```

**ä¼˜åŠ¿**ï¼š
- å®é™…è¾“å‡ºï¼ˆå¯é‡æ–°è¿è¡ŒéªŒè¯ï¼‰
- å…·ä½“æ•°å­—ï¼ˆ34/34ï¼‰
- æ˜ç¡®ç»“è®ºï¼ˆAll tests passï¼‰

---

#### åœºæ™¯ 2ï¼šBug ä¿®å¤éªŒè¯

**âŒ ä¸»è§‚å®£ç§°**ï¼š

```
AIï¼šFixed the bug. The code change should resolve the issue.
ç”¨æˆ·ï¼šDid you test it?
AIï¼šThe logic looks correct, so it should work.
```

**é—®é¢˜**ï¼š
- "looks correct" â‰  å®é™…å·¥ä½œ
- æ— å…·ä½“éªŒè¯æ­¥éª¤
- å‡è®¾è€ŒééªŒè¯

---

**âœ… è¯æ®é©±åŠ¨**ï¼ˆsystematic-debugging æŠ€èƒ½ï¼‰ï¼š

```markdown
### Phase 4: Implementation

Fix the root cause, not the symptom:

1. **Create Failing Test Case**
   - Simplest possible reproduction
   - Automated test if possible
   - One-off test script if no framework
   - MUST have before fixing

2. **Implement Single Fix**
   - Address the root cause identified
   - ONE change at a time

3. **Verify Fix**
   - Test passes now?
   - No other tests broken?
   - Issue actually resolved?
```

**ç¤ºä¾‹è¾“å‡º**ï¼š

```
Created test: test/user-login-failure.test.js

$ npm test test/user-login-failure.test.js

FAIL  test/user-login-failure.test.js
  âœ• User login rejects empty passwords
    Expected: { error: 'Password required' }
    Received: undefined

âœ… Test fails correctly (missing validation)

Implemented validation in login.js

$ npm test test/user-login-failure.test.js

PASS  test/user-login-failure.test.js
  âœ“ User login rejects empty passwords

âœ… Bug fixed, test passes
```

---

#### åœºæ™¯ 3ï¼šAgent å§”æ‰˜éªŒè¯

**âŒ ä¸»è§‚å®£ç§°**ï¼š

```
AIï¼šDispatched agent to implement feature...
     [agent returns]
Agent reports: Implementation complete, all tests passing.

Great! The feature is ready.
```

**é—®é¢˜**ï¼š
- ä¿¡ä»» Agent æŠ¥å‘Š
- æ— ç‹¬ç«‹éªŒè¯
- Agent å¯èƒ½"å¹»è§‰"

---

**âœ… è¯æ®é©±åŠ¨**ï¼ˆspec-reviewer æŠ€èƒ½ï¼‰ï¼š

```markdown
## CRITICAL: Do Not Trust the Report

The implementer finished suspiciously quickly. Their report may be incomplete,
inaccurate, or optimistic. You MUST verify everything independently.

**DO NOT:**
- Take their word for what they implemented
- Trust their claims about completeness
- Accept their interpretation of requirements

**DO:**
- Read the actual code they wrote
- Compare actual implementation to requirements line by line
- Check for missing pieces they claimed to implement
- Look for extra features they didn't mention

**Verify by reading code, not by trusting report.**

Report:
- âœ… Spec compliant (if everything matches after code inspection)
- âŒ Issues found: [list specifically what's missing or extra, with file:line references]
```

---

### è¯æ®éªŒè¯æ¨¡æ¿

#### æ¨¡æ¿ 1ï¼šå‘½ä»¤ + è¾“å‡º + ç»“è®º

```markdown
**[Category]:**
```
âœ… [Run verification command] [See: evidence] "Conclusion"
âŒ [Subjective claim] / [Insufficient verification]
```

**ä½¿ç”¨åœºæ™¯**ï¼šç®€å•çš„å•ä¸€éªŒè¯

**ç¤ºä¾‹**ï¼š

```markdown
**Tests:**
```
âœ… [Run `npm test`] [See: 47/47 pass] "All tests pass"
âŒ "Should pass now" / "Tests look good"
```

---

#### æ¨¡æ¿ 2ï¼šæµç¨‹åŒ–éªŒè¯

```markdown
## The Gate Function

```
BEFORE claiming [status]:

1. IDENTIFY: What [type] proves this claim?
2. [Action 1]
3. [Action 2]
4. [Action 3]
5. ONLY THEN: [Make claim]

Skip any step = [consequence]
```

**ä½¿ç”¨åœºæ™¯**ï¼šéœ€è¦å¤šæ­¥éª¤çš„éªŒè¯

**ç¤ºä¾‹**ï¼ˆverification-before-completionï¼‰ï¼š

```markdown
## The Gate Function

```
BEFORE claiming any status or expressing satisfaction:

1. IDENTIFY: What command proves this claim?
2. RUN: Execute FULL command (fresh, complete)
3. READ: Full output, check exit code, count failures
4. VERIFY: Does output confirm to claim?
   - If NO: State actual status with evidence
   - If YES: State claim WITH evidence
5. ONLY THEN: Make the claim

Skip any step = lying, not verifying
```

---

#### æ¨¡æ¿ 3ï¼šè¡¨æ ¼åŒ–éªŒè¯è¦æ±‚

```markdown
## Common Failures

| Claim | Requires | Not Sufficient |
|-------|----------|----------------|
| [Claim type 1] | [Required evidence] | [Insufficient evidence 1] |
| [Claim type 2] | [Required evidence] | [Insufficient evidence 2] |
| [Claim type 3] | [Required evidence] | [Insufficient evidence 3] |
```

**ä½¿ç”¨åœºæ™¯**ï¼šå¤šç§éªŒè¯åœºæ™¯

**ç¤ºä¾‹**ï¼ˆverification-before-completionï¼‰ï¼š

```markdown
## Common Failures

| Claim | Requires | Not Sufficient |
|-------|----------|----------------|
| Tests pass | Test command output: 0 failures | Previous run, "should pass" |
| Linter clean | Linter output: 0 errors | Partial check, extrapolation |
| Build succeeds | Build command: exit 0 | Linter passing, logs look good |
| Bug fixed | Test original symptom: passes | Code changed, assumed fixed |
| Regression test works | Red-green cycle verified | Test passes once |
| Agent completed | VCS diff shows changes | Agent reports "success" |
| Requirements met | Line-by-line checklist | Tests passing |
```

---

## å·¥ä½œæµæ¨¡å¼ï¼šå¤šå±‚å®¡æŸ¥æœºåˆ¶

å¤šå±‚å®¡æŸ¥é€šè¿‡**è§’è‰²åˆ†ç¦»**å’Œ**èŒè´£æ˜ç¡®**å½¢æˆé˜²å¾¡çºµæ·±ï¼Œæ¯ä¸ªå®¡æŸ¥è€…å…³æ³¨å•ä¸€ç»´åº¦ï¼Œé¿å…è§’è‰²æ··æ·†å¯¼è‡´çš„é—æ¼ã€‚

### å®¡æŸ¥å±‚æ¬¡è®¾è®¡

#### å±‚æ¬¡ 1ï¼šè‡ªæˆ‘å®¡æŸ¥ï¼ˆImplementerï¼‰

**èŒè´£**ï¼š
- å®Œæ•´æ€§ï¼šæ˜¯å¦å®ç°äº†æ‰€æœ‰éœ€æ±‚
- è´¨é‡ï¼šæ˜¯å¦æ˜¯æœ€ä½³å·¥ä½œ
- çºªå¾‹ï¼šæ˜¯å¦éµå¾ª YAGNIã€DRYã€TDD
- æµ‹è¯•ï¼šæµ‹è¯•æ˜¯å¦æœ‰æ•ˆ

**æ¥è‡ª implementer-prompt æ¨¡æ¿**ï¼š

```markdown
## Before Reporting Back: Self-Review

Review your work with fresh eyes. Ask yourself:

**Completeness:**
- Did I fully implement everything in the spec?
- Did I miss any requirements?
- Are there edge cases I didn't handle?

**Quality:**
- Is this my best work?
- Are names clear and accurate (match what things do, not how they work)?
- Is the code clean and maintainable?

**Discipline:**
- Did I avoid overbuilding (YAGNI)?
- Did I only build what was requested?
- Did I follow existing patterns in the codebase?

**Testing:**
- Do tests actually verify behavior (not just mock behavior)?
- Did I follow TDD if required?
- Are tests comprehensive?

If you find issues during self-review, fix them now before reporting.
```

**å…³é”®ç‰¹ç‚¹**ï¼š
- é—®é¢˜å¼æ£€æŸ¥ï¼ˆ"Did I..."ï¼‰
- è¦†ç›–å¤šä¸ªç»´åº¦ï¼ˆå®Œæ•´æ€§ã€è´¨é‡ã€çºªå¾‹ã€æµ‹è¯•ï¼‰
- è¦æ±‚ç°åœ¨ä¿®å¤ï¼ˆ"fix them now"ï¼‰

---

#### å±‚æ¬¡ 2ï¼šè§„èŒƒç¬¦åˆæ€§å®¡æŸ¥ï¼ˆSpec Compliance Reviewerï¼‰

**èŒè´£**ï¼š
- éªŒè¯ä¸å¤šä¸å°‘
- å¯¹æ¯”ä»£ç  vs éœ€æ±‚
- è¯†åˆ«è¯¯è§£

**æ¥è‡ª spec-reviewer-prompt æ¨¡æ¿**ï¼š

```markdown
## CRITICAL: Do Not Trust the Report

The implementer finished suspiciously quickly. Their report may be incomplete,
inaccurate, or optimistic. You MUST verify everything independently.

**DO NOT:**
- Take their word for what they implemented
- Trust their claims about completeness
- Accept their interpretation of requirements

**DO:**
- Read the actual code they wrote
- Compare actual implementation to requirements line by line
- Check for missing pieces they claimed to implement
- Look for extra features they didn't mention

## Your Job

Read the implementation code and verify:

**Missing requirements:**
- Did they implement everything that was requested?
- Are there requirements they skipped or missed?
- Did they claim something works but didn't actually implement it?

**Extra/unneeded work:**
- Did they build things that weren't requested?
- Did they over-engineer or add unnecessary features?
- Did they add "nice to haves" that weren't in spec?

**Misunderstandings:**
- Did they interpret requirements differently than intended?
- Did they solve the wrong problem?
- Did they implement the right feature but wrong way?

**Verify by reading code, not by trusting report.**

Report:
- âœ… Spec compliant (if everything matches after code inspection)
- âŒ Issues found: [list specifically what's missing or extra, with file:line references]
```

**å…³é”®ç‰¹ç‚¹**ï¼š
- ä¸ä¿¡ä»»æŠ¥å‘Šï¼ˆç‹¬ç«‹éªŒè¯ï¼‰
- ä¸‰ä¸ªæ£€æŸ¥ç»´åº¦ï¼ˆç¼ºå¤±ã€é¢å¤–ã€è¯¯è§£ï¼‰
- è¦æ±‚å…·ä½“å¼•ç”¨ï¼ˆfile:lineï¼‰

---

#### å±‚æ¬¡ 3ï¼šä»£ç è´¨é‡å®¡æŸ¥ï¼ˆCode Quality Reviewerï¼‰

**èŒè´£**ï¼š
- ä»£ç é£æ ¼
- æ¶æ„éµå¾ª
- æœ€ä½³å®è·µ
- å®‰å…¨æ€§ã€æ€§èƒ½

**æ¥è‡ª code-quality-reviewer-prompt æ¨¡æ¿**ï¼š

```markdown
**Purpose:** Verify implementation is well-built (clean, tested, maintainable)

**Only dispatch after spec compliance review passes.**

```
Task tool (superpowers:code-reviewer):
  Use template at requesting-code-review/code-reviewer.md

  WHAT_WAS_IMPLEMENTED: [from implementer's report]
  PLAN_OR_REQUIREMENTS: Task N from [plan-file]
  BASE_SHA: [commit before task]
  HEAD_SHA: [current commit]
  DESCRIPTION: [task summary]
```

**Code reviewer returns:** Strengths, Issues (Critical/Important/Minor), Assessment
```

**æ¥è‡ª code-reviewer.md**ï¼š

```markdown
You are a Senior Code Reviewer with expertise in software architecture,
design patterns, and best practices. Your role is to review completed
project steps against original plans and ensure code quality standards are met.

When reviewing completed work, you will:

1. **Plan Alignment Analysis:**
   - Compare to original planning document or step description
   - Identify any deviations from planned approach
   - Assess whether deviations are justified improvements or problematic departures
   - Verify all planned functionality has been implemented

2. **Code Quality Assessment:**
   - Review for adherence to established patterns and conventions
   - Check for proper error handling, type safety, defensive programming
   - Evaluate code organization, naming conventions, maintainability
   - Assess test coverage and quality of test implementations
   - Look for potential security vulnerabilities or performance issues

3. **Architecture and Design Review:**
   - Ensure SOLID principles and established architectural patterns
   - Check for proper separation of concerns and loose coupling
   - Verify code integrates well with existing systems
   - Assess scalability and extensibility considerations

4. **Issue Identification and Recommendations:**
   - Clearly categorize issues: Critical (must fix), Important (should fix), Suggestions (nice to have)
   - For each issue, provide specific examples and actionable recommendations
   - When you identify plan deviations, explain whether they're problematic or beneficial
   - Suggest specific improvements with code examples when helpful

Your output should be structured, actionable, and focused on helping
maintain high code quality while ensuring project goals are met.
```

**å…³é”®ç‰¹ç‚¹**ï¼š
- é«˜è´¨é‡æ ‡å‡†ï¼ˆSenior Code Reviewerï¼‰
- åˆ†ç±»é—®é¢˜ï¼ˆCritical/Important/Minorï¼‰
- å¯æ“ä½œå»ºè®®

---

### å®¡æŸ¥æµç¨‹å›¾

```mermaid
graph TD
    A[Implementer] --> B[Self-Review]
    B -->|Self-approve| C[Spec Compliance Reviewer]
    B -->|Fix issues| A
    C -->|Spec compliant| D[Code Quality Reviewer]
    C -->|Issues found| A
    D -->|Ready| E[Task Complete]
    D -->|Critical/Important issues| A
    D -->|Minor issues| F[Note for later]
```

---

### å®¡æŸ¥æ¨¡æ¿åº“

#### æ¨¡æ¿ 1ï¼šè‡ªæˆ‘å®¡æŸ¥æ¸…å•

```markdown
## Before [Action]: Self-Review

Review your work with fresh eyes. Ask yourself:

**[Dimension 1]:**
- [Question 1]
- [Question 2]

**[Dimension 2]:**
- [Question 1]
- [Question 2]

**[Dimension 3]:**
- [Question 1]
- [Question 2]

If you find issues, [what to do].
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```markdown
## Before Reporting Back: Self-Review

Review your work with fresh eyes. Ask yourself:

**Completeness:**
- Did I fully implement everything in the spec?
- Did I miss any requirements?

**Quality:**
- Is this my best work?
- Are names clear and accurate?

**Testing:**
- Do tests actually verify behavior?
- Did I follow TDD if required?

If you find issues, fix them now before reporting.
```

---

#### æ¨¡æ¿ 2ï¼šç‹¬ç«‹éªŒè¯æç¤º

```markdown
## CRITICAL: Do Not Trust the [Source]

[Why distrust is necessary].

**DO NOT:**
- [Don't 1]
- [Don't 2]
- [Don't 3]

**DO:**
- [Do 1]
- [Do 2]
- [Do 3]

**Verify by [method], not by trusting [source].**

Report:
- âœ… [Success condition]
- âŒ [Failure condition]: [what to report]
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```markdown
## CRITICAL: Do Not Trust the Report

The implementer finished suspiciously quickly. You MUST verify independently.

**DO NOT:**
- Take their word for what they implemented
- Trust their claims about completeness
- Accept their interpretation

**DO:**
- Read actual code they wrote
- Compare to requirements line by line
- Check for missing pieces
- Look for extra features

**Verify by reading code, not by trusting report.**

Report:
- âœ… Spec compliant (after code inspection)
- âŒ Issues found: [list with file:line references]
```

---

#### æ¨¡æ¿ 3ï¼šåˆ†ç±»é—®é¢˜æŠ¥å‘Š

```markdown
**[Reviewer] returns:** Strengths, Issues ([Critical/Important/Minor]), Assessment

**Issue Categories:**

| Severity | Must | Should | Nice |
|----------|-------|--------|------|
| [Description] | [What to do] | [When to do] | [Optional] |

**Output Format:**

```markdown
**Strengths:**
- [Strength 1]
- [Strength 2]

**Issues:**
- **Critical:** [Issue] â†’ [Action required]
- **Important:** [Issue] â†’ [Action required]
- **Minor:** [Issue] â†’ [Note for later]

**Assessment:** [Overall judgment]
```
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```markdown
**Code reviewer returns:** Strengths, Issues (Critical/Important/Minor), Assessment

**Issue Categories:**

| Severity | Must | Should | Nice |
|----------|-------|--------|------|
| Critical | Fix before proceeding | - | - |
| Important | Fix before proceeding | Fix before merge | - |
| Minor | - | Fix when convenient | Note for later |

**Output Format:**

```markdown
**Strengths:**
- Clean architecture
- Real tests
- Good documentation

**Issues:**
- **Critical:** Missing error handling in retry logic â†’ Fix before proceeding
- **Important:** No type safety in API layer â†’ Fix before merge
- **Minor:** Magic number (100) for reporting interval â†’ Note for later

**Assessment:** Ready to proceed after Critical/Important issues fixed
```
```

---

## å®ç”¨æ¨¡æ¿åº“

æœ¬èŠ‚æä¾›å¯ç›´æ¥ä½¿ç”¨çš„æç¤ºè¯æ¨¡æ¿ï¼Œæ¶µç›–å¸¸è§åœºæ™¯ã€‚

### æ¨¡æ¿ 1ï¼šTDD å¾ªç¯

```markdown
---
name: test-driven-development
description: Use when implementing any feature or bugfix, before writing implementation code
---

# Test-Driven Development (TDD)

## Overview

Write the test first. Watch it fail. Write minimal code to pass.

**Core principle:** If you didn't watch the test fail, you don't know if it tests the right thing.

## The Iron Law

```
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
```

Write code before test? Delete it. Start over.

## Red-Green-Refactor Cycle

### RED - Write Failing Test

Write one minimal test showing what should happen.

**Requirements:**
- One behavior
- Clear name
- Real code (no mocks unless unavoidable)

### Verify RED - Watch It Fail

**MANDATORY. Never skip.**

```bash
[Run test command]
```

Confirm:
- Test fails (not errors)
- Failure message is expected
- Fails because feature missing

**Test passes?** You're testing existing behavior. Fix test.

### GREEN - Minimal Code

Write simplest code to pass the test.

Don't add features, refactor other code, or "improve" beyond the test.

### Verify GREEN - Watch It Pass

**MANDATORY.**

```bash
[Run test command]
```

Confirm:
- Test passes
- Other tests still pass
- Output pristine

### REFACTOR - Clean Up

After green only:
- Remove duplication
- Improve names
- Extract helpers

Keep tests green. Don't add behavior.

## Verification Checklist

Before marking work complete:

- [ ] Every new function/method has a test
- [ ] Watched each test fail before implementing
- [ ] Each test failed for expected reason
- [ ] Wrote minimal code to pass each test
- [ ] All tests pass
- [ ] Tests use real code
- [ ] Edge cases covered
```

---

### æ¨¡æ¿ 2ï¼šè¯æ®éªŒè¯ç½‘å…³

```markdown
---
name: verification-before-completion
description: Use when about to claim work is complete, before committing or creating PRs
---

# Verification Before Completion

## Overview

Claiming work is complete without verification is dishonesty, not efficiency.

**Core principle:** Evidence before claims, always.

## The Iron Law

```
NO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE
```

If you haven't run the verification command in this message, you cannot claim it passes.

## The Gate Function

```
BEFORE claiming any status or expressing satisfaction:

1. IDENTIFY: What command proves this claim?
2. RUN: Execute FULL command (fresh, complete)
3. READ: Full output, check exit code, count failures
4. VERIFY: Does output confirm to claim?
   - If NO: State actual status with evidence
   - If YES: State claim WITH evidence
5. ONLY THEN: Make the claim

Skip any step = lying, not verifying
```

## Key Patterns

**Tests:**
```
âœ… [Run test] [See: X/X pass] "All tests pass"
âŒ "Should pass now" / "Looks correct"
```

**Build:**
```
âœ… [Run build] [See: exit 0] "Build succeeds"
âŒ "Linter passed" (linter â‰  compiler)
```

**Bug fix:**
```
âœ… Test original symptom: passes "Bug fixed"
âŒ Code changed, assumed fixed
```

## Red Flags - STOP

- Using "should", "probably", "seems to"
- Expressing satisfaction before verification
- About to commit/push/PR without verification
- Trusting agent success reports
- Relying on partial verification
- **ANY wording implying success without evidence**
```

---

### æ¨¡æ¿ 3ï¼šç³»ç»Ÿæ€§è°ƒè¯•

```markdown
---
name: systematic-debugging
description: Use when encountering any bug, test failure, or unexpected behavior
---

# Systematic Debugging

## Overview

Random fixes waste time and create new bugs. Quick patches mask underlying issues.

**Core principle:** ALWAYS find root cause before attempting fixes.

## The Iron Law

```
NO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST
```

If you haven't completed Phase 1, you cannot propose fixes.

## The Four Phases

### Phase 1: Root Cause Investigation

**BEFORE attempting ANY fix:**

1. **Read Error Messages Carefully**
   - Don't skip errors or warnings
   - Read stack traces completely
   - Note line numbers, file paths, error codes

2. **Reproduce Consistently**
   - Can you trigger it reliably?
   - What are exact steps?

3. **Check Recent Changes**
   - Git diff, recent commits
   - New dependencies, config changes

### Phase 2: Pattern Analysis

1. **Find Working Examples**
   - Locate similar working code in codebase

2. **Compare Against References**
   - Read reference implementation COMPLETELY
   - Understand pattern fully before applying

### Phase 3: Hypothesis and Testing

1. **Form Single Hypothesis**
   - State clearly: "I think X is root cause because Y"

2. **Test Minimally**
   - Smallest possible change
   - One variable at a time
   - Don't fix multiple things at once

### Phase 4: Implementation

1. **Create Failing Test Case**
   - Simplest possible reproduction
   - MUST have before fixing

2. **Implement Single Fix**
   - Address root cause identified
   - ONE change at a time

3. **Verify Fix**
   - Test passes now?
   - No other tests broken?
   - Issue actually resolved?

4. **If 3+ Fixes Failed: Question Architecture**

Each fix reveals new problem = architectural problem.

**STOP and question:**
- Is this pattern fundamentally sound?
- Should we refactor architecture vs. continue fixing?

## Red Flags

- "Quick fix for now, investigate later"
- "Just try changing X and see if it works"
- "Add multiple changes, run tests"
- "One more fix attempt" (after 2+ failures)
```

---

### æ¨¡æ¿ 4ï¼šç‹¬ç«‹è§„èŒƒå®¡æŸ¥

```markdown
---
name: spec-compliance-review
description: Use to verify implementation matches requirements exactly (nothing more, nothing less)
---

# Spec Compliance Reviewer

## Purpose

Verify implementer built what was requested (nothing more, nothing less).

## CRITICAL: Do Not Trust the Report

The implementer finished suspiciously quickly. Their report may be incomplete,
inaccurate, or optimistic. You MUST verify everything independently.

**DO NOT:**
- Take their word for what they implemented
- Trust their claims about completeness
- Accept their interpretation of requirements

**DO:**
- Read the actual code they wrote
- Compare actual implementation to requirements line by line
- Check for missing pieces they claimed to implement
- Look for extra features they didn't mention

## Your Job

Read the implementation code and verify:

**Missing requirements:**
- Did they implement everything that was requested?
- Are there requirements they skipped or missed?
- Did they claim something works but didn't actually implement it?

**Extra/unneeded work:**
- Did they build things that weren't requested?
- Did they over-engineer or add unnecessary features?
- Did they add "nice to haves" that weren't in spec?

**Misunderstandings:**
- Did they interpret requirements differently than intended?
- Did they solve the wrong problem?
- Did they implement the right feature but wrong way?

**Verify by reading code, not by trusting report.**

## Report Format

- âœ… Spec compliant (if everything matches after code inspection)
- âŒ Issues found: [list specifically what's missing or extra, with file:line references]
```

---

### æ¨¡æ¿ 5ï¼šä»£ç è´¨é‡å®¡æŸ¥

```markdown
---
name: code-quality-review
description: Use to verify implementation is well-built, tested, and maintainable
---

# Code Quality Reviewer

## Purpose

Verify implementation is well-built (clean, tested, maintainable).

**Only dispatch after spec compliance review passes.**

## Review Criteria

1. **Plan Alignment Analysis:**
   - Compare to original planning document
   - Identify deviations from planned approach
   - Assess whether deviations are improvements or problematic
   - Verify all planned functionality implemented

2. **Code Quality Assessment:**
   - Adherence to established patterns and conventions
   - Proper error handling, type safety, defensive programming
   - Code organization, naming conventions, maintainability
   - Test coverage and quality
   - Security vulnerabilities, performance issues

3. **Architecture and Design Review:**
   - SOLID principles and architectural patterns
   - Separation of concerns and loose coupling
   - Integration with existing systems
   - Scalability and extensibility

4. **Issue Identification:**
   - Categorize: Critical (must fix), Important (should fix), Suggestions (nice to have)
   - Provide specific examples and actionable recommendations
   - Explain whether plan deviations are problematic or beneficial
   - Suggest improvements with code examples

## Output Format

```markdown
**Strengths:**
- [Strength 1]
- [Strength 2]

**Issues:**
- **Critical:** [Issue] â†’ [Action required]
- **Important:** [Issue] â†’ [Action required]
- **Minor:** [Issue] â†’ [Note for later]

**Assessment:** [Overall judgment and next steps]
```

## Integration

Use with:
- Spec compliance review (must pass first)
- Git SHAs for diff review (BASE_SHA, HEAD_SHA)
```

---

## å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ

### é™·é˜± 1ï¼šæè¿°è¿‡é•¿æˆ–è¿‡çŸ­

#### é—®é¢˜ï¼š

```yaml
# âŒ å¤ªé•¿
description: |
  This skill helps you follow test-driven development
  principles by writing tests before implementation code.
  It enforces the RED-GREEN-REFACTOR cycle and
  ensures that you watch each test fail before
  implementing the feature...

# âŒ å¤ªçŸ­
description: Helps with tests
```

#### è§£å†³æ–¹æ¡ˆï¼š

```yaml
# âœ… æ­£ç¡®
description: Use when implementing any feature or bugfix, before writing implementation code
```

**åŸåˆ™**ï¼š
- 100-150 å­—ç¬¦
- åŒ…å«ä½¿ç”¨æ¡ä»¶ï¼ˆwhen...ï¼‰
- åŒ…å«è§¦å‘è¯ï¼ˆfeature, bugfix, implementationï¼‰
- åŠ¨ä½œå¯¼å‘ï¼ˆbefore writingï¼‰

---

### é™·é˜± 2ï¼šé“å¾‹æªè¾ä¸å¤Ÿç»å¯¹

#### é—®é¢˜ï¼š

```markdown
# âŒ å¤ªå¼±
## Important Rule

You should really try to write tests before code.
If you don't, please at least add them after.

## Iron Law
```

#### è§£å†³æ–¹æ¡ˆï¼š

```markdown
# âœ… æ­£ç¡®
## The Iron Law

```
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
```

Write code before test? Delete it. Start over.

**No exceptions:**
- Don't keep it as "reference"
- Don't "adapt" it while writing tests
- Don't look at it
- Delete means delete
```

**åŸåˆ™**ï¼š
- å…¨å¤§å†™
- ç»å¯¹åŒ–ï¼ˆNOã€WITHOUTã€PERIODï¼‰
- æ˜ç¡®åæœï¼ˆDelete itï¼‰
- æ¶ˆé™¤ä¾‹å¤–ï¼ˆNo exceptionsï¼‰

---

### é™·é˜± 3ï¼šæµç¨‹æ­¥éª¤ä¸å¤Ÿå…·ä½“

#### é—®é¢˜ï¼š

```markdown
# âŒ å¤ªæ¨¡ç³Š
## The Process

1. Write a test for the feature
2. Implement the code to make it pass
3. Run tests to verify
4. Clean up the code if needed
```

**é—®é¢˜**ï¼šæ¯ä¸€æ­¥å¯ä»¥æœ‰å¤šç§è§£è¯»ï¼ŒAI å¯èƒ½"åˆç†åŒ–"åç¦»ã€‚

#### è§£å†³æ–¹æ¡ˆï¼š

```markdown
# âœ… å…·ä½“å¯æ“ä½œ
## Red-Green-Refactor Cycle

### RED - Write Failing Test

Write one minimal test showing what should happen.

**Requirements:**
- One behavior
- Clear name
- Real code (no mocks unless unavoidable)

### Verify RED - Watch It Fail

**MANDATORY. Never skip.**

```bash
npm test path/to/test.test.ts
```

Confirm:
- Test fails (not errors)
- Failure message is expected
- Fails because feature missing (not typos)

**Test passes?** You're testing existing behavior. Fix test.
```

**åŸåˆ™**ï¼š
- æ¯æ­¥æœ‰å­æ­¥éª¤
- æ˜ç¡®å‘½ä»¤ï¼ˆbash ä»£ç å—ï¼‰
- æ˜ç¡®éªŒè¯æ ‡å‡†ï¼ˆConfirm: ...ï¼‰
- æ˜ç¡®å¼‚å¸¸å¤„ç†ï¼ˆTest passes? Fix testï¼‰

---

### é™·é˜± 4ï¼šæ²¡æœ‰é¢„åˆ¤å¸¸è§åˆç†åŒ–

#### é—®é¢˜ï¼š

```markdown
# âŒ ç¼ºå¤±é˜²å¾¡
## The Iron Law

Write test before code.

If you write code first, delete it.
```

**é—®é¢˜**ï¼šç”¨æˆ·/AI ä¼šæƒ³"è¿™æ¬¡ç‰¹æ®Š"ã€"å¤ªç®€å•ä¸éœ€è¦"

#### è§£å†³æ–¹æ¡ˆï¼š

```markdown
# âœ… é¢„åˆ¤åé©³
## The Iron Law

```
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
```

Write code before test? Delete it. Start over.

## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "Too simple to test" | Simple code breaks. Test takes 30 seconds. |
| "I'll test after" | Tests passing immediately prove nothing. |
| "Already manually tested" | Ad-hoc â‰  systematic. No record, can't re-run. |
| "Deleting X hours is wasteful" | Sunk cost fallacy. Your choice now: Delete and rewrite with TDD (X more hours, high confidence) OR Keep it and add tests after (30 min, low confidence, likely bugs) |
```

**åŸåˆ™**ï¼š
- åˆ—å‡ºå¸¸è§å€Ÿå£
- ç”¨ç®€çŸ­å¯¹æ¯”åé©³
- é‡åŒ–åæœï¼ˆæ—¶é—´ã€ä¿¡å¿ƒã€bug ç‡ï¼‰

---

### é™·é˜± 5ï¼šéªŒè¯ä¸å¤Ÿä¸¥æ ¼

#### é—®é¢˜ï¼š

```markdown
# âŒ å…è®¸éƒ¨åˆ†éªŒè¯
## Verification

Before claiming completion, run the tests to make sure everything works.
```

**é—®é¢˜**ï¼š"make sure everything works" æ˜¯ä¸»è§‚åˆ¤æ–­ã€‚

#### è§£å†³æ–¹æ¡ˆï¼š

```markdown
# âœ… ä¸¥æ ¼éªŒè¯
## The Gate Function

```
BEFORE claiming any status or expressing satisfaction:

1. IDENTIFY: What command proves this claim?
2. RUN: Execute FULL command (fresh, complete)
3. READ: Full output, check exit code, count failures
4. VERIFY: Does output confirm to claim?
   - If NO: State actual status with evidence
   - If YES: State claim WITH evidence
5. ONLY THEN: Make the claim

Skip any step = lying, not verifying
```

**åŸåˆ™**ï¼š
- æµç¨‹åŒ–ï¼ˆ5 æ­¥ï¼‰
- å®¢è§‚è¯æ®ï¼ˆcommand output, exit codeï¼‰
- è¦æ±‚å®Œå…¨ï¼ˆFULL commandï¼‰
- åªæœ‰æˆåŠŸæ‰å®£ç§°ï¼ˆONLY THENï¼‰

---

## ä»ç¤ºä¾‹åˆ°å®è·µï¼šå®Œæ•´æ¡ˆä¾‹

è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå®Œæ•´æ¡ˆä¾‹ï¼Œå°†æ‰€å­¦åº”ç”¨äºåˆ›å»ºä¸€ä¸ªæ–°æŠ€èƒ½ã€‚

### åœºæ™¯ï¼šä»£ç å®¡æŸ¥å“åº”

**éœ€æ±‚**ï¼šåˆ›å»ºä¸€ä¸ªæŠ€èƒ½ï¼ŒæŒ‡å¯¼ AI å¦‚ä½•å›åº”ä»£ç å®¡æŸ¥åé¦ˆã€‚

#### æ­¥éª¤ 1ï¼šåˆ†æéœ€æ±‚

**é—®é¢˜**ï¼š
- AI å¯èƒ½è¿‡åº¦é˜²å¾¡ï¼ˆ"ä¸å¯¹ï¼Œæˆ‘çš„ä»£ç æ˜¯å¯¹çš„"ï¼‰
- AI å¯èƒ½ç›²ç›®æ¥å—æ‰€æœ‰å»ºè®®
- AI å¯èƒ½ä¸çŸ¥é“å¦‚ä½•åŒºåˆ†å…³é”®/æ¬¡è¦é—®é¢˜

**ç›®æ ‡**ï¼š
- æä¾›ç»“æ„åŒ–çš„å›åº”æµç¨‹
- åŒºåˆ†é—®é¢˜ç±»å‹
- æä¾›å…·ä½“è¡ŒåŠ¨æŒ‡å—

---

#### æ­¥éª¤ 2ï¼šè®¾è®¡å…ƒæ•°æ®

```yaml
---
name: receiving-code-review
description: Use when responding to code review feedback - classify issues, address appropriately, and push back on incorrect feedback with technical reasoning
---
```

**æ£€æŸ¥ç‚¹**ï¼š
- âœ… `name` æ¸…æ™°ï¼š`receiving-code-review`
- âœ… `description` åŒ…å«è§¦å‘æ¡ä»¶ï¼ˆwhen respondingï¼‰å’ŒåŠ¨ä½œï¼ˆclassify, address, push backï¼‰
- âœ… é•¿åº¦é€‚ä¸­ï¼šçº¦ 130 å­—ç¬¦

---

#### æ­¥éª¤ 3ï¼šç¼–å†™ Overview

```markdown
# Receiving Code Review

## Overview

Not all review feedback requires changes. Some requests reflect misunderstanding
or preference differences. Respond appropriately: fix real issues, explain
design decisions, push back on incorrect feedback.

**Core principle:** Technical correctness over submission to authority.
```

**æ£€æŸ¥ç‚¹**ï¼š
- âœ… ç®€æ´æ ¸å¿ƒåŸåˆ™
- âœ… ä¸€å¥è¯è¯´æ˜
- âœ… å¿…è¦æ—¶åŠ è§£é‡Š

---

#### æ­¥éª¤ 4ï¼šè®¾è®¡ Iron Law

```markdown
## The Iron Law

```
NO DEFENSIVENESS, NO BLIND ACCEPTANCE
```

Critical and Important issues must be fixed before proceeding.
Push back only with technical reasoning. Explain with evidence.

**Never:**
- Argue based on ego or preference
- Accept feedback without understanding
- Ignore Critical or Important issues
```

**æ£€æŸ¥ç‚¹**ï¼š
- âœ… å…¨å¤§å†™
- âœ… ä»£ç å—æ ¼å¼
- âœ… ç«‹å³åæœè¯´æ˜
- âœ… æ¶ˆé™¤ä¾‹å¤–ï¼ˆNeverï¼‰

---

#### æ­¥éª¤ 5ï¼šç»“æ„åŒ–ä½¿ç”¨åœºæ™¯

```markdown
## When to Use

**Use when:**
- Code review feedback is received
- Reviewer identifies issues (Critical, Important, Minor)
- Reviewer makes suggestions or requests changes

**Especially important when:**
- Reviewer disagrees with design choices
- Feedback seems incorrect or based on misunderstanding
- Multiple issues of varying severity are reported

**Don't skip when:**
- Feedback seems minor
- You agree with most points
- Reviewer is junior or less experienced
```

**æ£€æŸ¥ç‚¹**ï¼š
- âœ… æ˜ç¡®ä½¿ç”¨æ¡ä»¶
- âœ… å¼ºè°ƒé‡è¦æƒ…å†µ
- âœ… æ¶ˆé™¤å¸¸è§å€Ÿå£ï¼ˆDon't skip whenï¼‰

---

#### æ­¥éª¤ 6ï¼šè®¾è®¡æµç¨‹

```markdown
## The Response Process

### Step 1: Classify Issues

For each issue identified by reviewer:

| Issue Type | Required Action | Timing |
|------------|----------------|---------|
| **Critical** | Must fix | Before proceeding |
| **Important** | Should fix | Before merging |
| **Minor** | Note for later | When convenient |
| **Suggestion** | Consider | Based on judgment |

### Step 2: Address Each Issue

**For issues to fix:**
1. Implement the fix
2. Verify tests still pass
3. Explain what changed

**For issues to push back:**
1. Identify the misunderstanding
2. Explain with technical reasoning
3. Provide evidence (code/tests/docs)
4. Request clarification if unsure

### Step 3: Respond Structure

```markdown
**[Issue Severity]: [Issue description]**

**Your action:** [What you did / what you're pushing back on]

**[If fixing:]**
- Changed: [summary of change]
- Reason: [why reviewer was right]

**[If pushing back:]**
- Reason: [technical explanation]
- Evidence: [code/tests/docs supporting your approach]
- Request: [what you need from reviewer]
```

### Step 4: Update and Re-verify

After fixing issues:
1. Commit changes with descriptive message
2. Run full test suite
3. Report summary: "Fixed X issues, pushed back on Y with reasoning"
```

**æ£€æŸ¥ç‚¹**ï¼š
- âœ… æµç¨‹æ¸…æ™°ï¼ˆ4 æ­¥ï¼‰
- âœ… æ¯æ­¥å¯æ“ä½œ
- âœ… åŒ…å«æ¨¡æ¿ï¼ˆResponse Structureï¼‰
- âœ… æ˜ç¡®éªŒè¯è¦æ±‚

---

#### æ­¥éª¤ 7ï¼šé¢„åˆ¤å¸¸è§é™·é˜±

```markdown
## Common Pitfalls

| Trap | What to Avoid | Better Approach |
|------|--------------|----------------|
| **Defensive ego** | "No, my code is perfect" | "Here's why I chose this approach..." |
| **Blind acceptance** | "Sure, I'll change everything" | "This makes sense, but let me explain..." |
| **Ignoring feedback** | Skip Critical issues | Address all Critical and Important |
| **Weak pushback** | "I don't think so..." | "The spec requires X because..." |

## Red Flags - STOP

- Thinking "this reviewer doesn't understand"
- Arguing based on "I prefer" or "I like"
- Accepting feedback without verifying
- Ignoring issues because "it works"
- Pushing back without evidence or reasoning
```

**æ£€æŸ¥ç‚¹**ï¼š
- âœ… è¯†åˆ«å¸¸è§é™·é˜±
- âœ… æä¾›æ›¿ä»£æ–¹æ¡ˆ
- âœ… åˆ—å‡º Red Flags
- âœ… æ¯ä¸ªé™·é˜±æœ‰ What to Avoid å’Œ Better Approach

---

#### æ­¥éª¤ 8ï¼šæ·»åŠ ç¤ºä¾‹

```markdown
## Examples

### Example 1: Fixing Critical Issue

**Reviewer feedback:**
```
- **Critical:** Missing error handling in retry logic â†’ Fix before proceeding
```

**Your response:**

```markdown
**Critical: Missing error handling in retry logic**

**Your action:** Fixed

- Changed: Added try-catch around retry attempts, now propagates
  network errors with proper error codes
- Reason: You're right - unhandled errors were causing silent failures

```

Commit: fix(retry): add error handling and error codes
Tests: All passing (34/34)
```

### Example 2: Pushing Back with Reasoning

**Reviewer feedback:**
```
- **Important:** No type safety in API layer â†’ Fix before merge
```

**Your response:**

```markdown
**Important: No type safety in API layer**

**Your action:** Pushing back with reasoning

**Reason:** The API layer uses a dynamic DSL by design.
  Adding TypeScript interfaces would require runtime validation
  anyway, which adds overhead without safety benefits.

**Evidence:**
- Spec at docs/api-dsl.md: "Dynamic typing for flexibility"
- Tests at test/api-dsl.test.js: Cover type coercion edge cases
- Production: Running for 6 months with no type-related bugs

**Request:** Please review the DSL design and tests.
  If you strongly believe static typing is needed, let's discuss
  the architectural tradeoffs.
```

### Example 3: Accepting Suggestions

**Reviewer feedback:**
```
- **Suggestion:** Magic number (100) for reporting interval â†’ Note for later
```

**Your response:**

```markdown
**Suggestion: Magic number (100) for reporting interval**

**Your action:** Noted for later refactoring

I agree this should be configurable. Adding to technical debt
tracker to address in next sprint.

For now, the 100ms interval is:
- Documented in docs/performance.md
- Sufficient for current load (10K requests/sec)
- Safe (verified through load testing)

Will refactor: Add REPORT_INTERVAL_MS config parameter
```

**æ£€æŸ¥ç‚¹**ï¼š
- âœ… æ¯ä¸ªåœºæ™¯æœ‰å®Œæ•´ç¤ºä¾‹
- âœ… åŒ…å«å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆReviewer + Your responseï¼‰
- âœ… æ¯ä¸ªç¤ºä¾‹å±•ç¤ºä¸åŒå¤„ç†æ–¹å¼ï¼ˆfix, push back, acceptï¼‰
- âœ… åŒ…å«è¯æ®å’Œç†ç”±

---

#### æ­¥éª¤ 9ï¼šéªŒè¯æ¸…å•

```markdown
## Verification Checklist

Before responding to code review:

- [ ] Classified all issues (Critical/Important/Minor/Suggestion)
- [ ] Fixed all Critical issues
- [ ] Fixed all Important issues (or have agreed deferral)
- [ ] Noted all Minor issues for later
- [ ] Considered all Suggestions
- [ ] For pushbacks: Have technical reasoning + evidence
- [ ] Verified tests still pass after fixes
- [ ] Committed changes with descriptive messages
- [ ] Reported summary of actions taken
```

**æ£€æŸ¥ç‚¹**ï¼š
- âœ… å¯å‹¾é€‰æ¡†
- âœ… è¦†ç›–æ‰€æœ‰æ­¥éª¤
- âœ… å…·ä½“å¯éªŒè¯

---

#### æ­¥éª¤ 10ï¼šæœ€ç»ˆæŠ€èƒ½æ–‡ä»¶

```markdown
---
name: receiving-code-review
description: Use when responding to code review feedback - classify issues, address appropriately, and push back on incorrect feedback with technical reasoning
---

# Receiving Code Review

## Overview

Not all review feedback requires changes. Some requests reflect misunderstanding
or preference differences. Respond appropriately: fix real issues, explain
design decisions, push back on incorrect feedback.

**Core principle:** Technical correctness over submission to authority.

## The Iron Law

```
NO DEFENSIVENESS, NO BLIND ACCEPTANCE
```

Critical and Important issues must be fixed before proceeding.
Push back only with technical reasoning. Explain with evidence.

**Never:**
- Argue based on ego or preference
- Accept feedback without understanding
- Ignore Critical or Important issues

## When to Use

**Use when:**
- Code review feedback is received
- Reviewer identifies issues (Critical, Important, Minor)
- Reviewer makes suggestions or requests changes

**Especially important when:**
- Reviewer disagrees with design choices
- Feedback seems incorrect or based on misunderstanding
- Multiple issues of varying severity are reported

**Don't skip when:**
- Feedback seems minor
- You agree with most points
- Reviewer is junior or less experienced

## The Response Process

### Step 1: Classify Issues

For each issue identified by reviewer:

| Issue Type | Required Action | Timing |
|------------|----------------|---------|
| **Critical** | Must fix | Before proceeding |
| **Important** | Should fix | Before merging |
| **Minor** | Note for later | When convenient |
| **Suggestion** | Consider | Based on judgment |

### Step 2: Address Each Issue

**For issues to fix:**
1. Implement the fix
2. Verify tests still pass
3. Explain what changed

**For issues to push back:**
1. Identify the misunderstanding
2. Explain with technical reasoning
3. Provide evidence (code/tests/docs)
4. Request clarification if unsure

### Step 3: Respond Structure

```markdown
**[Issue Severity]: [Issue description]**

**Your action:** [What you did / what you're pushing back on]

**[If fixing:]**
- Changed: [summary of change]
- Reason: [why reviewer was right]

**[If pushing back:]**
- Reason: [technical explanation]
- Evidence: [code/tests/docs supporting your approach]
- Request: [what you need from reviewer]
```

### Step 4: Update and Re-verify

After fixing issues:
1. Commit changes with descriptive message
2. Run full test suite
3. Report summary: "Fixed X issues, pushed back on Y with reasoning"

## Common Pitfalls

| Trap | What to Avoid | Better Approach |
|------|--------------|----------------|
| **Defensive ego** | "No, my code is perfect" | "Here's why I chose this approach..." |
| **Blind acceptance** | "Sure, I'll change everything" | "This makes sense, but let me explain..." |
| **Ignoring feedback** | Skip Critical issues | Address all Critical and Important |
| **Weak pushback** | "I don't think so..." | "The spec requires X because..." |

## Red Flags - STOP

- Thinking "this reviewer doesn't understand"
- Arguing based on "I prefer" or "I like"
- Accepting feedback without verifying
- Ignoring issues because "it works"
- Pushing back without evidence or reasoning

## Examples

### Example 1: Fixing Critical Issue

**Reviewer feedback:**
```
- **Critical:** Missing error handling in retry logic â†’ Fix before proceeding
```

**Your response:**

```markdown
**Critical: Missing error handling in retry logic**

**Your action:** Fixed

- Changed: Added try-catch around retry attempts, now propagates
  network errors with proper error codes
- Reason: You're right - unhandled errors were causing silent failures

```

Commit: fix(retry): add error handling and error codes
Tests: All passing (34/34)
```

### Example 2: Pushing Back with Reasoning

**Reviewer feedback:**
```
- **Important:** No type safety in API layer â†’ Fix before merge
```

**Your response:**

```markdown
**Important: No type safety in API layer**

**Your action:** Pushing back with reasoning

**Reason:** The API layer uses a dynamic DSL by design.
  Adding TypeScript interfaces would require runtime validation
  anyway, which adds overhead without safety benefits.

**Evidence:**
- Spec at docs/api-dsl.md: "Dynamic typing for flexibility"
- Tests at test/api-dsl.test.js: Cover type coercion edge cases
- Production: Running for 6 months with no type-related bugs

**Request:** Please review the DSL design and tests.
  If you strongly believe static typing is needed, let's discuss
  the architectural tradeoffs.
```

### Example 3: Accepting Suggestions

**Reviewer feedback:**
```
- **Suggestion:** Magic number (100) for reporting interval â†’ Note for later
```

**Your response:**

```markdown
**Suggestion: Magic number (100) for reporting interval**

**Your action:** Noted for later refactoring

I agree this should be configurable. Adding to technical debt
tracker to address in next sprint.

For now, the 100ms interval is:
- Documented in docs/performance.md
- Sufficient for current load (10K requests/sec)
- Safe (verified through load testing)

Will refactor: Add REPORT_INTERVAL_MS config parameter
```

## Verification Checklist

Before responding to code review:

- [ ] Classified all issues (Critical/Important/Minor/Suggestion)
- [ ] Fixed all Critical issues
- [ ] Fixed all Important issues (or have agreed deferral)
- [ ] Noted all Minor issues for later
- [ ] Considered all Suggestions
- [ ] For pushbacks: Have technical reasoning + evidence
- [ ] Verified tests still pass after fixes
- [ ] Committed changes with descriptive messages
- [ ] Reported summary of actions taken

## Integration

**Used by:**
- Implementers responding to code review
- Anyone receiving feedback on their work

**Pairs with:**
- **requesting-code-review** (initiates the review process)
```

---

### æ­¥éª¤ 11ï¼šè‡ªè¯„

**å¯¹ç…§æ¨¡æ¿æ£€æŸ¥**ï¼š

| æ¨¡æ¿å…ƒç´  | çŠ¶æ€ |
|---------|------|
| å…ƒæ•°æ® | âœ… |
| Overview | âœ… |
| Iron Law | âœ… |
| When to Use | âœ… |
| æµç¨‹æ­¥éª¤ | âœ… |
| å¸¸è§é™·é˜± | âœ… |
| Red Flags | âœ… |
| ç¤ºä¾‹ | âœ… |
| éªŒè¯æ¸…å• | âœ… |
| Integration | âœ… |

**å…³é”®ä¼˜åŠ¿**ï¼š
1. æ¸…æ™°çš„åˆ†ç±»ï¼ˆCritical/Important/Minor/Suggestionï¼‰
2. æ˜ç¡®çš„å“åº”ç»“æ„æ¨¡æ¿
3. ä¸°å¯Œçš„ç¤ºä¾‹è¦†ç›–ä¸åŒåœºæ™¯
4. é¢„åˆ¤å¸¸è§é™·é˜±å¹¶æä¾› Better Approach

---

## ç»“è¯­ï¼šä»åŸç†åˆ°å®è·µ

### æ ¸å¿ƒå›é¡¾

Superpowers çš„æç¤ºè¯å·¥ç¨‹æˆåŠŸåœ¨äºï¼š

1. **ç³»ç»Ÿæ€§ä¼˜äºéšæœºæ€§**ï¼šå°†éšæ€§çš„æœ€ä½³å®è·µæ˜¾æ€§åŒ–ä¸ºå¯é‡å¤çš„æµç¨‹
2. **è¯æ®ä¼˜äºå®£ç§°**ï¼šè¦æ±‚å®¢è§‚éªŒè¯è€Œéä¸»è§‚å£°ç§°
3. **è§’è‰²åˆ†ç¦»ä¼˜äºæ··æ·†**ï¼šæ¯ä¸ªå®¡æŸ¥è€…å…³æ³¨å•ä¸€ç»´åº¦
4. **é¢„é˜²ä¼˜äºè¡¥æ•‘**ï¼šé¢„åˆ¤å¿ƒç†é™·é˜±å¹¶æå‰åé©³

### åº”ç”¨å»ºè®®

**å¯¹äºä¸ªäººå¼€å‘è€…**ï¼š
1. ä» 1-2 ä¸ªæŠ€èƒ½å¼€å§‹ï¼Œä¸è¦è¯•å›¾ä¸€æ¬¡æ€§åº”ç”¨æ‰€æœ‰æ¨¡å¼
2. å…³æ³¨æ ¸å¿ƒåŸç†ï¼Œè€Œéæ­»è®°æ¨¡æ¿
3. æ”¶é›†è‡ªå·±çš„å¤±è´¥æ¡ˆä¾‹ï¼Œè¯†åˆ«æ¨¡å¼

**å¯¹äºå›¢é˜Ÿå·¥å…·æ„å»ºè€…**ï¼š
1. å»ºç«‹ç»Ÿä¸€çš„æŠ€èƒ½æ¨¡æ¿åº“
2. å®šæœŸå®¡æŸ¥å’Œè¿­ä»£æŠ€èƒ½
3. æ”¶é›†ç”¨æˆ·åé¦ˆï¼ŒæŒç»­æ”¹è¿›

**å¯¹äºç ”ç©¶è€…å’Œå·¥å…·å¼€å‘è€…**ï¼š
1. ç ”ç©¶ Superpowers çš„æˆåŠŸè¦ç´ 
2. æ¢ç´¢æ–°çš„æç¤ºè¯è®¾è®¡æ¨¡å¼
3. åˆ†äº«æœ€ä½³å®è·µ

### è¿›ä¸€æ­¥å­¦ä¹ 

**æ¨èé˜…è¯»**ï¼š
- [obra/superpowers GitHub ä»“åº“](https://github.com/obra/superpowers)
- Superpowers é¡¹ç›®ä¸­çš„æ‰€æœ‰æŠ€èƒ½æ–‡ä»¶
- [Anthropic Skills æ–‡æ¡£](https://docs.anthropic.com)

**å®è·µå»ºè®®**ï¼š
1. ä¸ºä½ çš„é¡¹ç›®åˆ›å»ºä¸€ä¸ªæŠ€èƒ½
2. åœ¨å®é™…ä½¿ç”¨ä¸­è§‚å¯Ÿæ•ˆæœ
3. æ ¹æ®è§‚å¯Ÿç»“æœè¿­ä»£æ”¹è¿›

---

**æ•™ç¨‹ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2026-02-04
**ä½œè€…**: åŸºäº obra/superpowers é¡¹ç›®åˆ†æ

---

## é™„å½•ï¼šå¿«é€Ÿå‚è€ƒ

### å…ƒæ•°æ®æ¨¡æ¿

```yaml
---
name: skill-name
description: Use when [trigger], before [action] or when [context]
---
```

### Iron Law æ¨¡æ¿

```markdown
## The Iron Law

```
[ABSOLUTE RULE IN ALL CAPS]
```

[Immediate consequence].

**No exceptions:**
- [Not even when...]
```

### éªŒè¯ç½‘å…³æ¨¡æ¿

```markdown
## The Gate Function

```
BEFORE [action]:

1. IDENTIFY: [what]
2. RUN: [command]
3. READ: [what to check]
4. VERIFY: [how to confirm]
5. ONLY THEN: [make claim]

Skip any step = [consequence]
```

### Common Rationalizations æ¨¡æ¿

```markdown
## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "[Common excuse]" | [Why it's wrong, concisely |
```

---

**Happy Prompt Engineering! ğŸš€**
