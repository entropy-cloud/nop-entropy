# Necessary Conditions GPT Must Satisfy for Producing Complex Code

Many people are trying to have GPT directly generate code, attempting to guide GPT to complete traditional programming tasks via natural language. However, almost no one seriously considers how the generated code will be maintained over the long term.

Based on the fundamental concepts of Reversible Computation theory, we can reason as follows:

1. If a piece of complex business-logic code is to run stably over the long term, it’s clearly impossible to regenerate the code from scratch each time the requirements change. We must revise the original logic in a controlled, delta-ized manner, so we must define a Delta space and ensure that in this space the program can automatically perform delta merge operations. Reasoning further: if we want to ensure the stability of a delta description of a complex system, it must be defined in a domain-model space with business meaning, rather than in a general-purpose programming language space. The general-purpose language space is too large and misaligned with the requirement space. A small requirement change can trigger massive shifts in the general-purpose language space, undermining the stability of the logical expression.

2. Given the inherent ambiguity of natural language, the stable carrier for complex business logic should not be natural language. Even if a natural-language description is unambiguous in today’s context, as social contexts shift and word meanings drift, that same phrasing could be interpreted differently in the future. To express business logic in a stable and precise way and guarantee absolutely reproducible execution with the specified semantics, we need to use the brilliant pinnacle of human intelligence achieved in the last 100 years: formal language. To ensure that formal-language logic automatically generated by GPT can be understood by people and rapidly verified and checked, it should provide a descriptive language whose complexity matches the business requirements, one that can be automatically verified by tools and from which information can be reverse-extracted for other uses: a Domain-Specific Language (DSL).

3. Program code stores a great deal of business knowledge, but previous programming technologies often locked that knowledge inside specific technical implementations, and we lack general techniques to extract it back out. Even if GPT can read a chunk of existing code and produce a natural-language explanation of it, it’s still difficult to write a program that accurately extracts the exact knowledge we need from the system’s source code. GPT’s code explanations can serve as references but may hallucinate at any time. However, if we are using GPT to build a new system, why not from the outset use a structural expression that supports reversible analysis?

4. If GPT doesn’t just complete tasks via simple Q&A but can call external plugins and design relatively complex execution plans, then—whether from a security perspective or from the perspective of stable external interactions—we need to constrain the commands GPT issues to a pre-defined semantic space.

Some programmers may not value theoretical analysis, believing that prompt engineering for AI large models is purely a matter of accumulated practical experience. I disagree. In fact, based on the analysis above from Reversible Computation theory, we naturally obtain the necessary conditions for using GPT as a serious software production tool:

GPT’s input and output should be delta-ized DSL (domain language) descriptions.

## A Forest of DSLs Built on a Unified Metamodel

Many people believe that GPT can understand complex business-logic descriptions and generate accurate general-purpose code implementations. If so, why can’t GPT master a structurally simpler DSL with a clearer semantic definition? A common misunderstanding is that DSLs use custom, niche syntaxes, and large language models lack sufficient training data to learn such grammars. In reality, what matters in DSLs is the domain semantic space they establish. They use domain-specific terminology to concisely express related business knowledge and can naturally map to user requirement descriptions. For example, to describe a user approval flow, we only need a few concepts such as process, step, action, and approver. Every token used in a DSL carries business semantics, rather than being added because of technical constraints. In contrast, if we use a general-purpose language, we inevitably involve details irrelevant to the business—such as importing dependency packages and declaring variable scopes—arising from language syntax constraints.

If we focus only on DSL semantics, we can absolutely adopt general XML or JSON syntax as the DSL’s universal syntax. Put simply, a DSL can be defined in the form of an AST (syntax tree). This approach is similar to LISP’s S-expressions, except we can use more readable XML tags. Different representations can be reversibly converted. For example, the Nop Platform defines multiple reversible conversions between XML and JSON; essentially, both JSON and XML can represent the same DSL.

With a unified representation syntax, different DSLs can be constrained using a unified metamodel (similar to JSON Schema), and thereby form a forest of DSLs. Leveraging a unified metamodel, the DSL forest can achieve consistent semantic understanding and support seamless embedding among multiple DSLs.

Many programmers traditionally think that designing a new DSL requires hand-writing a parser, a compiler, and even maintaining IDE plugins—an enormous workload. But in the Nop Platform, you only need to define an XDef metamodel to automatically obtain a parser, a validator, IDE syntax hints, and even the ability to set breakpoints and step-debug directly in IDEA! The Nop Platform can also automatically implement bidirectional conversion between domain objects and Excel template files (convert an Excel document into a DSL description, or export an Excel document from a DSL description), and can automatically generate visual designers, etc. The Nop Platform offers the concept of a Domain Language Workbench, enabling rapid development and expansion of DSLs. Its design goal is similar to JetBrains’ MPS, but the Nop Platform is built on the concepts of Reversible Computation theory. Its technical approach is simpler and clearer, with much lower complexity than MPS, while greatly surpassing MPS in flexibility and extensibility.

## Why XML Is a Suitable Syntax Carrier for DSLs

Many programmers have never personally designed an XML-format DSL. They have only heard tales from veterans about how XML, in ancient times, was dethroned by newer contenders, and have formed a stereotype that XML is too verbose, suitable only for machine-to-machine data exchange, and unsuitable for human-computer interaction. This is a mistaken prejudice, stemming from XML fundamentalism’s misuse of XML, and from a series of international XML specifications that amplified such misuses.

When some people think of expressing logic in XML, the stereotype that may come to mind is:

```xml
<function>
   <name>myFunc</name>
   <args>
      <arg>
         <arg>
           <name>arg1</name>
           <value>3</value>
         </arg>
         <arg>
           <arg>
              <name>arg2</name>
              <value>aaa</value>
           </arg>
         </arg>
      </arg>
   </args>
</function>
```

But in practice, we can just use the following XML:

```xml
<myFunc arg1="3" arg2="aa" />
```

If we need to express that the type of the arg1 parameter value is an integer rather than a string, we can extend the XML syntax to allow numeric attribute values directly. Or, similar to the Vue framework, we can add a specific prefix to distinguish whether a value is a string; for example, stipulate that the `@:` prefix indicates that the subsequent value conforms to JSON syntax and can be parsed as JSON.

```xml
<myFunc arg1=3 arg2="aa" /> 或者
<myFunc arg1="@:3" arg2="aa" />
```

In the Nop Platform, we define rules for bidirectional conversion between JSON and XML. For example, for the following AMIS page description:

```json
{
  "type": "crud",
  "draggable": true,
  "bulkActions": [
    {
      "type": "button",
      "label": "批量删除",
      "actionType": "ajax",
      "api": "delete:/amis/api/mock2/sample/${ids|raw}",
      "confirmText": "确定要批量删除?"
    },
    {
      "type": "button",
      "label": "批量修改",
      "actionType": "dialog",
      "dialog": {
        "title": "批量编辑",
        "name": "sample-bulk-edit",
        "body": {
          "type": "form",
          "api": "/amis/api/mock2/sample/bulkUpdate2",
          "body": [
            {
              "type": "hidden",
              "name": "ids"
            },
            {
              "type": "input-text",
              "name": "engine",
              "label": "Engine"
            }
          ]
        }
      }
    }
  ]
}
```

The corresponding XML format is:

```xml
<crud draggable="@:true">
  <bulkActions j:list="true">
    <button label="批量删除" actionType="ajax" confirmText="确定要批量删除?">
      <api>delete:/amis/api/mock2/sample/${ids|raw}</api>
    </button>
    <button label="批量修改" actionType="dialog">
      <dialog title="批量编辑" name="sample-bulk-edit">
        <body>
           <form>
             <api>/amis/api/mock2/sample/bulkUpdate2</api>
             <body>
               <hidden name="ids" />
               <input-text name="engine" label="Engine" />
             </body>
           </form>
        </body>
      </dialog>
    </button>
  </bulkActions>
</crud>
```

In fact, the XML syntax looks more compact and intuitive.

> Here we use JSON-XML conversion without metamodel constraints, so we need j:list to mark array elements and use the @: prefix to represent non-string values. If the XML file has an XDef metamodel definition, these extra annotations are not necessary.

Another benefit of XML over JSON is that it can easily introduce XML extension tags for code generation, allowing both the code representation and the code-generation result to be in XML format. In the Lisp world, this is called homoiconicity. At present, JSON lacks a homoiconic approach to code generation.

```xml
<columns>
  <c:for var="col" items="${entityModel.columns}">
    <column name="${col.name}" sqlType="${col.sqlType}" />
  </c:for>
</columns>
```

For further discussion of the equivalence of XML and JSON, see: [The Equivalence of XML, JSON, and Function ASTs](https://zhuanlan.zhihu.com/p/554294376)

## AI Needs to Understand Metamodels

Large AI models caused a sensation mainly because they exhibit complex logical reasoning capabilities beyond simple pattern memorization. With this capability, LLMs should not need large amounts of program corpora to learn a DSL; it’s sufficient to tell them the language’s internal structural constraints.

The discovery of metamodels and metalanguages is among the most revolutionary in mathematics in the last 100 years. Metamodels and metalanguages hold special importance in mathematics; the development of category theory is closely related to model theory and research into metalanguages. In software development, we should be able to use metamodels to convey DSL syntactic structure and local semantic knowledge precisely to LLMs. Concretely, a metamodel can essentially be seen as a schema definition similar to JSON Schema.

In the Nop Platform, we emphasize a homomorphic relationship between metamodels and concrete model objects. That is, the form of the schema should be fundamentally consistent with the structure of the data itself, rather than, as in XML Schema, splitting a tree-like domain structure into many object-attribute relationships and expressing it in a completely different syntax. For example:

```xml
<entity name="test.MyEntity" table="my_entity">
  <columns>
    <column name="SID" sqlType="VARCHAR" length="30" />
    <column name="TITLE" sqlType="VARCHAR" length="200" />
  </columns>
</entity>
对应的XDef元模型定义为:

<entity name="!class-name" table="!string">
   <columns xdef:body-type="list" xdef:key-attr="name">
     <column name="!prop-name" sqlType="!std-sql-type" length="int" />
  </columns>
</entity>
```

Basically, XDef replaces specific values with stdDomain definitions, and for list elements retains only a single entry.

> stdDomain is similar to a type declaration, but it can be extended by users. All stdDomains are maintained in a dictionary and can impose local semantic constraints on field values. For example, class-name means the value must satisfy Java class naming requirements; not all strings are allowed. An exclamation mark before a stdDomain indicates the attribute value cannot be null.

Current large models are trained primarily via fill-in-the-blank approaches, so this homomorphic design also helps them quickly grasp metamodels. In today’s LLM applications, given a few samples, models can reverse-infer corresponding schema constraints, but such guesses are certainly inaccurate. For instance, it’s hard to teach a model via samples that certain string formats are illegal—such as disallowing hyphens as connectors. Through metamodels, we can quickly and efficiently transmit domain knowledge to large models.

Therefore, I believe the training of large models should intentionally strengthen metamodel training. Metamodels should be distinguished from ordinary models, and it is worth expending extra effort to improve a model’s precise mastery of metamodels.

For a concrete attempt at interacting with GPT using metamodels, see my article: [A Verified Strategy for GPT-Driven Low-Code Platforms to Produce Complete Applications](https://zhuanlan.zhihu.com/p/614745000)

## Concrete Strategy for Combining the Nop Platform with GPT

The Nop Platform’s strategy for communicating with GPT is as follows:

1. Use the xdef metamodel of the currently used DSL to help GPT understand the DSL structure more quickly and accurately.
2. Use delta merge rules from Reversible Computation to guide GPT to directly return delta descriptions.
3. Merge the returned delta into the current model to become the new current model; on this basis, you can interact with GPT indefinitely.
4. Complex logical reasoning often cannot be solved in one step with a single DSL. In this case, we can build a Delta pipeline using multiple DSLs, decomposing the problem into several steps to solve it.
   ![](../tutorial/delta-pipeline.png)

Based on the DSL support provided by the Nop Platform, AI and humans can collaborate as follows:

1. AI produces the top-level DSL according to the requirement specification.

2. A human-written code generator expands the DSL into the next-level DSL.

3. Humans can refine and adjust the AI-generated DSL using Delta customization.

4. For the finest details, AI can further refine based on local knowledge.

In short: 1) AI produces the rough cut, 2) humans refine it, 3) AI polishes.

Many programmers currently imagine AI code generation as producing interfaces, classes, properties, and other common software components. The Nop Platform takes a completely different approach. As I keep emphasizing, the class-property abstraction is a consequence of constraints from underlying implementation technologies and does not fully correspond to internal domain structures. For example, I’ve repeatedly stressed that when mapping the concept of domain structural coordinates to the type level, information is lost, making precise delta corrections impossible. The DSL in the Nop Platform is oriented toward Tree structures and can produce an entire logical tree in one shot.

Some might think of fine-tuning previously generated code structures by having an AI model generate a series of API calls to adjust the model. For example, generating an API to remove the phone3 field from the data model:

```
 entityModel.getColumns().remove("phone3“);
```

If we compare this with the Nop Platform’s delta merge operator, we can see why the API approach is suboptimal:

```
<columns>
   <column name="phone3" x:override="remove" />
   <column name="status" sqlType="INTEGER" />
</columns>
```

The Nop approach offers the following advantages:

1. Multiple Delta modifications can be merged into one result, and during merging they can be simplified, discarding redundant changes. The API approach essentially uses modification actions as Deltas, but multiple actions cannot be automatically merged or simplified. If we don’t mentally execute each action one by one, we can’t understand what the system will ultimately look like. This is exactly what Reversible Computation theory emphasizes: a Delta should be independently understandable and independently definable, and Deltas should satisfy the associative law and allow local simplification.

2. Deltas defined on domain models can be automatically analyzed by programs, with information reverse-extracted from them. If we implement Deltas via APIs, we don’t have simple tools to analyze the composition of a Delta; before applying it, we can’t precisely know its scope of impact, etc. This reverse information extraction capability is also a central emphasis of Reversible Computation theory.

3. The reason a Delta can be applied to a base model is that we can precisely define where the change occurs—for example, at the field named phone3 within the entity model’s field collection. This positional definition should be a path with clear business meaning and uniqueness. In contrast, locating “lines 10 to 20 in the MyEntity model file” is unstable and imprecise. The Nop Platform’s Delta customization scheme accurately leverages the domain model’s coordinate system, while the API-call approach deeply hides the concept of coordinates inside function call chains. GPT may use ad hoc positional techniques during generation and miss the most effective direct positioning means within the domain coordinate system.

In practice, guided by Reversible Computation theory, by proactively re-examining concrete programming practices from the perspectives of metamodels, reversibility, and delta-ization, we can gain many new insights and identify directions for further improvement.

## Viewing Prompts from the Perspective of Reversible Computation

Some hard-core prompt designs can be naturally explained from the standpoint of Reversible Computation theory, such as the TaskPlan in [HuggingGPT](https://www.cnblogs.com/botai/p/HuggingGPT-task.html):

```
The AI assistant performs task parsing on user input, generating a list
of tasks with the following format:
[{"task": task, "id", task_id, "dep": dependency_task_ids,
"args": {"text": text, "image": URL, "audio": URL, "video": URL}}].
```

This prompt format is very close to an XDef metamodel definition. HuggingGPT’s operation is precisely to have GPT return DSL statements that satisfy the metamodel requirements.

Microsoft’s [guidance project](https://github.com/microsoft/guidance) adopts prompts in the following format:

```python
role_simulator = guidance('''
{{#system~}}
You are a helpful assistant
{{~/system}}

{{#user~}}
You will answer the user as {{role}} in the following conversation. At every step, I will provide you with the user input, as well as a comment reminding you of your instructions. Never talk about the fact that you are an AI, even if the user asks you. Always answer as {{role}}.
{{#if first_question}}You can also start the conversation.{{/if}}
{{~/user}}

{{~! The assistant either starts the conversation or not, depending on if this is the first or second agent }}
{{#assistant~}}
Ok, I will follow these instructions.
{{#if first_question}}Let me start the conversation now:
{{role}}: {{first_question}}{{/if}}
{{~/assistant}}

{{~! Then the conversation unrolls }}
{{~#geneach 'conversation' stop=False}}
{{#user~}}
User: {{set 'this.input' (await 'input')}}
Comment: Remember, answer as a {{role}}. Start your utterance with {{role}}:
{{~/user}}
```

Clearly, if we introduce a standardized, systematic tree-structured representation, both machines and humans benefit.

The low-code platform NopPlatform, designed based on Reversible Computation theory, is open source:

- gitee: [canonical-entropy/nop-entropy](https://gitee.com/canonical-entropy/nop-entropy)
- github: [entropy-cloud/nop-entropy](https://github.com/entropy-cloud/nop-entropy)
- Development example: [docs/tutorial/tutorial.md](https://gitee.com/canonical-entropy/nop-entropy/blob/master/docs/tutorial/tutorial.md)
- [Principles of Reversible Computation and an Introduction & Q&A on the Nop Platform_bilibili](https://www.bilibili.com/video/BV1u84y1w7kX/)
<!-- SOURCE_MD5:20a90c4f745988fd240789b43bace4b8-->
